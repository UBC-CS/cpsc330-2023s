{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw5.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPSC 330 - Applied Machine Learning \n",
    "\n",
    "## Homework 5: Putting it all together \n",
    "### Associated lectures: All material till lecture 13\n",
    "\n",
    "#### Due date: See the [Calendar](https://htmlpreview.github.io/?https://github.com/UBC-CS/cpsc330-2023s/blob/master/docs/calendar.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "0. [Submission instructions](#si)\n",
    "1. [Understanding the problem](#1)\n",
    "2. [Data splitting](#2)\n",
    "3. [EDA](#3)\n",
    "4. (Optional) [Feature engineering](#4)\n",
    "5. [Preprocessing and transformations](#5) \n",
    "6. [Baseline model](#6)\n",
    "7. [Linear models](#7)\n",
    "8. [Different models](#8)\n",
    "9. (Optional) [Feature selection](#9)\n",
    "10. [Hyperparameter optimization](#10)\n",
    "11. [Interpretation and feature importances](#11) \n",
    "12. [Results on the test set](#12)\n",
    "13. [Summary of the results](#13)\n",
    "14. (Optional) [Your takeaway from the course](#15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Submission instructions <a name=\"si\"></a>\n",
    "<hr>\n",
    "rubric={points:4}\n",
    "\n",
    "You will receive marks for correctly submitting this assignment. To submit this assignment, follow the instructions below:\n",
    "\n",
    "- **You may work on this assignment in a group (group size <= 4) and submit your assignment as a group.** \n",
    "- Below are some instructions on working as a group.  \n",
    "    - The maximum group size is 4. \n",
    "    - You can choose your own group members. \n",
    "    - Use group work as an opportunity to collaborate and learn new things from each other. \n",
    "    - Be respectful to each other and make sure you understand all the concepts in the assignment well. \n",
    "    - It's your responsibility to make sure that the assignment is submitted by one of the group members before the deadline. [Here](https://help.gradescope.com/article/m5qz2xsnjy-student-add-group-members) are some instructions on adding group members in Gradescope.  \n",
    "- Be sure to follow the [homework submission instructions](https://github.com/UBC-CS/cpsc330-2023s/blob/main/docs/homework_instructions.md).\n",
    "- Upload the .ipynb file to Gradescope.\n",
    "- **If the .ipynb file is too big or doesn't render on Gradescope for some reason, also upload a pdf or html in addition to the .ipynb.** \n",
    "- Make sure that your plots/output are rendered properly in Gradescope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import string\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from hashlib import sha1\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import tests_hw5\n",
    "from sklearn import datasets\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a name=\"in\"></a>\n",
    "\n",
    "In this homework you will be working on an open-ended mini-project, where you will put all the different things you have learned so far together to solve an interesting problem.\n",
    "\n",
    "A few notes and tips when you work on this mini-project: \n",
    "\n",
    "#### Tips\n",
    "1. This mini-project is open-ended, and while working on it, there might be some situations where you'll have to use your own judgment and make your own decisions (as you would be doing when you work as a data scientist). Make sure you explain your decisions whenever necessary. \n",
    "2. **Do not include everything you ever tried in your submission** -- it's fine just to have your final code. That said, your code should be reproducible and well-documented. For example, if you chose your hyperparameters based on some hyperparameter optimization experiment, you should leave in the code for that experiment so that someone else could re-run it and obtain the same hyperparameters, rather than mysteriously just setting the hyperparameters to some (carefully chosen) values in your code. \n",
    "3. If you realize that you are repeating a lot of code try to organize it in functions. Clear presentation of your code, experiments, and results is the key to be successful in this lab. You may use code from lecture notes or previous lab solutions with appropriate attributions. \n",
    "\n",
    "#### Assessment\n",
    "We plan to grade fairly and leniently. We don't have some secret target score that you need to achieve to get a good grade. **You'll be assessed on demonstration of mastery of course topics, clear presentation, and the quality of your analysis and results.** For example, if you just have a bunch of code and no text or figures, that's not good. If you do a bunch of sane things and get a lower accuracy than your friend, don't sweat it.\n",
    "\n",
    "\n",
    "#### A final note\n",
    "Finally, this style of this \"project\" question is different from other assignments. It'll be up to you to decide when you're \"done\" -- in fact, this is one of the hardest parts of real projects. But please don't spend WAY too much time on this... perhaps \"a few hours\" (15-20 hours???) is a good guideline for this project . Of course if you're having fun you're welcome to spend as much time as you want! But, if so, try not to do it out of perfectionism or getting the best possible grade. Do it because you're learning and enjoying it. Students from the past cohorts have found such kind of labs useful and fun and I hope you enjoy it as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 1. Pick your problem and explain the prediction problem <a name=\"1\"></a>\n",
    "<hr>\n",
    "rubric={points:3}\n",
    "\n",
    "In this mini project, you will be working on a classification problem of predicting whether a credit card client will default or not. \n",
    "For this problem, you will use [Default of Credit Card Clients Dataset](https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset). In this data set, there are 30,000 examples and 24 features, and the goal is to estimate whether a person will default (fail to pay) their credit card bills; this column is labeled \"default.payment.next.month\" in the data. The rest of the columns can be used as features. You may take some ideas and compare your results with [the associated research paper](https://www.sciencedirect.com/science/article/pii/S0957417407006719), which is available through [the UBC library](https://www.library.ubc.ca/). \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Spend some time understanding the problem and what each feature means. You can find this information in the documentation on [the dataset page on Kaggle](https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset). Write a few sentences on your initial thoughts on the problem and the dataset. \n",
    "2. Download the dataset and read it as a pandas dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_1\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272.0</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>3261.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331.0</td>\n",
       "      <td>14948.0</td>\n",
       "      <td>15549.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314.0</td>\n",
       "      <td>28959.0</td>\n",
       "      <td>29547.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940.0</td>\n",
       "      <td>19146.0</td>\n",
       "      <td>19131.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>36681.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>29996</td>\n",
       "      <td>220000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>88004.0</td>\n",
       "      <td>31237.0</td>\n",
       "      <td>15980.0</td>\n",
       "      <td>8500.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>5003.0</td>\n",
       "      <td>3047.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>29997</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>8979.0</td>\n",
       "      <td>5190.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1837.0</td>\n",
       "      <td>3526.0</td>\n",
       "      <td>8998.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>29998</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>20878.0</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>19357.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>29999</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>52774.0</td>\n",
       "      <td>11855.0</td>\n",
       "      <td>48944.0</td>\n",
       "      <td>85900.0</td>\n",
       "      <td>3409.0</td>\n",
       "      <td>1178.0</td>\n",
       "      <td>1926.0</td>\n",
       "      <td>52964.0</td>\n",
       "      <td>1804.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>30000</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>36535.0</td>\n",
       "      <td>32428.0</td>\n",
       "      <td>15313.0</td>\n",
       "      <td>2078.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  \\\n",
       "0          1    20000.0    2          2         1   24      2      2     -1   \n",
       "1          2   120000.0    2          2         2   26     -1      2      0   \n",
       "2          3    90000.0    2          2         2   34      0      0      0   \n",
       "3          4    50000.0    2          2         1   37      0      0      0   \n",
       "4          5    50000.0    1          2         1   57     -1      0     -1   \n",
       "...      ...        ...  ...        ...       ...  ...    ...    ...    ...   \n",
       "29995  29996   220000.0    1          3         1   39      0      0      0   \n",
       "29996  29997   150000.0    1          3         2   43     -1     -1     -1   \n",
       "29997  29998    30000.0    1          2         2   37      4      3      2   \n",
       "29998  29999    80000.0    1          3         1   41      1     -1      0   \n",
       "29999  30000    50000.0    1          2         1   46      0      0      0   \n",
       "\n",
       "       PAY_4  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  \\\n",
       "0         -1  ...        0.0        0.0        0.0       0.0     689.0   \n",
       "1          0  ...     3272.0     3455.0     3261.0       0.0    1000.0   \n",
       "2          0  ...    14331.0    14948.0    15549.0    1518.0    1500.0   \n",
       "3          0  ...    28314.0    28959.0    29547.0    2000.0    2019.0   \n",
       "4          0  ...    20940.0    19146.0    19131.0    2000.0   36681.0   \n",
       "...      ...  ...        ...        ...        ...       ...       ...   \n",
       "29995      0  ...    88004.0    31237.0    15980.0    8500.0   20000.0   \n",
       "29996     -1  ...     8979.0     5190.0        0.0    1837.0    3526.0   \n",
       "29997     -1  ...    20878.0    20582.0    19357.0       0.0       0.0   \n",
       "29998      0  ...    52774.0    11855.0    48944.0   85900.0    3409.0   \n",
       "29999      0  ...    36535.0    32428.0    15313.0    2078.0    1800.0   \n",
       "\n",
       "       PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \n",
       "0           0.0       0.0       0.0       0.0                           1  \n",
       "1        1000.0    1000.0       0.0    2000.0                           1  \n",
       "2        1000.0    1000.0    1000.0    5000.0                           0  \n",
       "3        1200.0    1100.0    1069.0    1000.0                           0  \n",
       "4       10000.0    9000.0     689.0     679.0                           0  \n",
       "...         ...       ...       ...       ...                         ...  \n",
       "29995    5003.0    3047.0    5000.0    1000.0                           0  \n",
       "29996    8998.0     129.0       0.0       0.0                           0  \n",
       "29997   22000.0    4200.0    2000.0    3100.0                           1  \n",
       "29998    1178.0    1926.0   52964.0    1804.0                           1  \n",
       "29999    1430.0    1000.0    1000.0    1000.0                           1  \n",
       "\n",
       "[30000 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/UCI_Credit_Card.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 2. Data splitting <a name=\"2\"></a>\n",
    "<hr>\n",
    "rubric={points:2}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Split the data into train (70%) and test (30%) portions with `random_state=123`.\n",
    "\n",
    "> If your computer cannot handle training on 70% training data, make the test split bigger.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_2\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    9815\n",
       "1    7433\n",
       "3    3416\n",
       "5     210\n",
       "4      81\n",
       "6      35\n",
       "0      10\n",
       "Name: EDUCATION, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['EDUCATION'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 3. EDA <a name=\"3\"></a>\n",
    "<hr>\n",
    "rubric={points:10}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Perform exploratory data analysis on the train set.\n",
    "2. Include at least two summary statistics and two visualizations that you find useful, and accompany each one with a sentence explaining it.\n",
    "3. Summarize your initial observations about the data. \n",
    "4. Pick appropriate metric/metrics for assessment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_3\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>2.100000e+04</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14962.348238</td>\n",
       "      <td>167880.651429</td>\n",
       "      <td>1.600762</td>\n",
       "      <td>1.852143</td>\n",
       "      <td>1.554000</td>\n",
       "      <td>35.500810</td>\n",
       "      <td>-0.015429</td>\n",
       "      <td>-0.137095</td>\n",
       "      <td>-0.171619</td>\n",
       "      <td>-0.225238</td>\n",
       "      <td>...</td>\n",
       "      <td>43486.610905</td>\n",
       "      <td>40428.518333</td>\n",
       "      <td>38767.202667</td>\n",
       "      <td>5673.585143</td>\n",
       "      <td>5.895027e+03</td>\n",
       "      <td>5311.432286</td>\n",
       "      <td>4774.021381</td>\n",
       "      <td>4751.850095</td>\n",
       "      <td>5237.762190</td>\n",
       "      <td>0.223238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8650.734050</td>\n",
       "      <td>130202.682167</td>\n",
       "      <td>0.489753</td>\n",
       "      <td>0.792961</td>\n",
       "      <td>0.521675</td>\n",
       "      <td>9.212644</td>\n",
       "      <td>1.120465</td>\n",
       "      <td>1.194506</td>\n",
       "      <td>1.196123</td>\n",
       "      <td>1.168556</td>\n",
       "      <td>...</td>\n",
       "      <td>64843.303993</td>\n",
       "      <td>61187.200817</td>\n",
       "      <td>59587.689549</td>\n",
       "      <td>17033.241454</td>\n",
       "      <td>2.180143e+04</td>\n",
       "      <td>18377.997079</td>\n",
       "      <td>15434.136142</td>\n",
       "      <td>15228.193125</td>\n",
       "      <td>18116.846563</td>\n",
       "      <td>0.416427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-50616.000000</td>\n",
       "      <td>-61372.000000</td>\n",
       "      <td>-339603.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7498.750000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2293.750000</td>\n",
       "      <td>1739.500000</td>\n",
       "      <td>1215.750000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>8.200000e+02</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>234.000000</td>\n",
       "      <td>110.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14960.500000</td>\n",
       "      <td>140000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>19102.500000</td>\n",
       "      <td>18083.000000</td>\n",
       "      <td>16854.500000</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>2.007000e+03</td>\n",
       "      <td>1809.500000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22458.250000</td>\n",
       "      <td>240000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>54763.250000</td>\n",
       "      <td>50491.000000</td>\n",
       "      <td>49253.750000</td>\n",
       "      <td>5007.250000</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>4628.500000</td>\n",
       "      <td>4021.250000</td>\n",
       "      <td>4016.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>891586.000000</td>\n",
       "      <td>927171.000000</td>\n",
       "      <td>961664.000000</td>\n",
       "      <td>873552.000000</td>\n",
       "      <td>1.227082e+06</td>\n",
       "      <td>896040.000000</td>\n",
       "      <td>621000.000000</td>\n",
       "      <td>426529.000000</td>\n",
       "      <td>528666.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID       LIMIT_BAL           SEX     EDUCATION      MARRIAGE  \\\n",
       "count  21000.000000    21000.000000  21000.000000  21000.000000  21000.000000   \n",
       "mean   14962.348238   167880.651429      1.600762      1.852143      1.554000   \n",
       "std     8650.734050   130202.682167      0.489753      0.792961      0.521675   \n",
       "min        1.000000    10000.000000      1.000000      0.000000      0.000000   \n",
       "25%     7498.750000    50000.000000      1.000000      1.000000      1.000000   \n",
       "50%    14960.500000   140000.000000      2.000000      2.000000      2.000000   \n",
       "75%    22458.250000   240000.000000      2.000000      2.000000      2.000000   \n",
       "max    30000.000000  1000000.000000      2.000000      6.000000      3.000000   \n",
       "\n",
       "                AGE         PAY_0         PAY_2         PAY_3         PAY_4  \\\n",
       "count  21000.000000  21000.000000  21000.000000  21000.000000  21000.000000   \n",
       "mean      35.500810     -0.015429     -0.137095     -0.171619     -0.225238   \n",
       "std        9.212644      1.120465      1.194506      1.196123      1.168556   \n",
       "min       21.000000     -2.000000     -2.000000     -2.000000     -2.000000   \n",
       "25%       28.000000     -1.000000     -1.000000     -1.000000     -1.000000   \n",
       "50%       34.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%       41.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       79.000000      8.000000      8.000000      8.000000      8.000000   \n",
       "\n",
       "       ...      BILL_AMT4      BILL_AMT5      BILL_AMT6       PAY_AMT1  \\\n",
       "count  ...   21000.000000   21000.000000   21000.000000   21000.000000   \n",
       "mean   ...   43486.610905   40428.518333   38767.202667    5673.585143   \n",
       "std    ...   64843.303993   61187.200817   59587.689549   17033.241454   \n",
       "min    ...  -50616.000000  -61372.000000 -339603.000000       0.000000   \n",
       "25%    ...    2293.750000    1739.500000    1215.750000    1000.000000   \n",
       "50%    ...   19102.500000   18083.000000   16854.500000    2100.000000   \n",
       "75%    ...   54763.250000   50491.000000   49253.750000    5007.250000   \n",
       "max    ...  891586.000000  927171.000000  961664.000000  873552.000000   \n",
       "\n",
       "           PAY_AMT2       PAY_AMT3       PAY_AMT4       PAY_AMT5  \\\n",
       "count  2.100000e+04   21000.000000   21000.000000   21000.000000   \n",
       "mean   5.895027e+03    5311.432286    4774.021381    4751.850095   \n",
       "std    2.180143e+04   18377.997079   15434.136142   15228.193125   \n",
       "min    0.000000e+00       0.000000       0.000000       0.000000   \n",
       "25%    8.200000e+02     390.000000     266.000000     234.000000   \n",
       "50%    2.007000e+03    1809.500000    1500.000000    1500.000000   \n",
       "75%    5.000000e+03    4628.500000    4021.250000    4016.000000   \n",
       "max    1.227082e+06  896040.000000  621000.000000  426529.000000   \n",
       "\n",
       "            PAY_AMT6  default.payment.next.month  \n",
       "count   21000.000000                21000.000000  \n",
       "mean     5237.762190                    0.223238  \n",
       "std     18116.846563                    0.416427  \n",
       "min         0.000000                    0.000000  \n",
       "25%       110.750000                    0.000000  \n",
       "50%      1500.000000                    0.000000  \n",
       "75%      4000.000000                    0.000000  \n",
       "max    528666.000000                    1.000000  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 21000 entries, 16395 to 19966\n",
      "Data columns (total 25 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   ID                          21000 non-null  int64  \n",
      " 1   LIMIT_BAL                   21000 non-null  float64\n",
      " 2   SEX                         21000 non-null  int64  \n",
      " 3   EDUCATION                   21000 non-null  int64  \n",
      " 4   MARRIAGE                    21000 non-null  int64  \n",
      " 5   AGE                         21000 non-null  int64  \n",
      " 6   PAY_0                       21000 non-null  int64  \n",
      " 7   PAY_2                       21000 non-null  int64  \n",
      " 8   PAY_3                       21000 non-null  int64  \n",
      " 9   PAY_4                       21000 non-null  int64  \n",
      " 10  PAY_5                       21000 non-null  int64  \n",
      " 11  PAY_6                       21000 non-null  int64  \n",
      " 12  BILL_AMT1                   21000 non-null  float64\n",
      " 13  BILL_AMT2                   21000 non-null  float64\n",
      " 14  BILL_AMT3                   21000 non-null  float64\n",
      " 15  BILL_AMT4                   21000 non-null  float64\n",
      " 16  BILL_AMT5                   21000 non-null  float64\n",
      " 17  BILL_AMT6                   21000 non-null  float64\n",
      " 18  PAY_AMT1                    21000 non-null  float64\n",
      " 19  PAY_AMT2                    21000 non-null  float64\n",
      " 20  PAY_AMT3                    21000 non-null  float64\n",
      " 21  PAY_AMT4                    21000 non-null  float64\n",
      " 22  PAY_AMT5                    21000 non-null  float64\n",
      " 23  PAY_AMT6                    21000 non-null  float64\n",
      " 24  default.payment.next.month  21000 non-null  int64  \n",
      "dtypes: float64(13), int64(12)\n",
      "memory usage: 4.2 MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                            21000.0\n",
       "LIMIT_BAL                     21000.0\n",
       "SEX                           21000.0\n",
       "EDUCATION                     21000.0\n",
       "MARRIAGE                      21000.0\n",
       "AGE                           21000.0\n",
       "PAY_0                         21000.0\n",
       "PAY_2                         21000.0\n",
       "PAY_3                         21000.0\n",
       "PAY_4                         21000.0\n",
       "PAY_5                         21000.0\n",
       "PAY_6                         21000.0\n",
       "BILL_AMT1                     21000.0\n",
       "BILL_AMT2                     21000.0\n",
       "BILL_AMT3                     21000.0\n",
       "BILL_AMT4                     21000.0\n",
       "BILL_AMT5                     21000.0\n",
       "BILL_AMT6                     21000.0\n",
       "PAY_AMT1                      21000.0\n",
       "PAY_AMT2                      21000.0\n",
       "PAY_AMT3                      21000.0\n",
       "PAY_AMT4                      21000.0\n",
       "PAY_AMT5                      21000.0\n",
       "PAY_AMT6                      21000.0\n",
       "default.payment.next.month    21000.0\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe().loc['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.776762\n",
       "1    0.223238\n",
       "Name: default.payment.next.month, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"default.payment.next.month\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "2. The mean for default.payment.next.month is 0.22, indicating that roughly a quarter of the examples will be a default.\n",
    "The count for all columns is 21000, indicating that all cells are filled and no imputations are needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.groupby(\"default.payment.next.month\")[\"PAY_0\"].plot.hist(bins=10, alpha=0.5, title=\"PAY_0\", legend=True)\n",
    "plt.show()\n",
    "# This histogram shows that those who delay payments by 2 or more months are far more likely to default on their payments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.groupby(\"default.payment.next.month\")[\"LIMIT_BAL\"].plot.hist(bins=10, alpha=0.5, title=\"LIMIT_BAL\", legend=True)\n",
    "plt.show()\n",
    "# This histogram shows that those with higher balance limits are proportionally less likely to default on payments\n",
    "# This makes sense as their limits should reflect the bank's trust in them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "3. No missing values.  \n",
    "All types are already numerical, either float or int.  Seems like usual categorical features such as sex, education, marriage, and pay (repayment status) have already been encoded, all ordinally.  The encodings don't make the most sense as sex could have been binary OHE, and education and marriage have \"unknown\" and \"other\" which may disrupt the numerical results.\n",
    "Slight class imbalance of around 1 default for every 3 non-defaults.\n",
    "The charts appear right skewed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "4. Recall would be a good metric for assessment since the bank is a business and would like to avoid lending to people who may default.\n",
    "F1 score may also be a good metric if the bank wants to maximize profit from loans by lending to as many people as possible, so it may also want to assess precision along with recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## (Optional) 4. Feature engineering <a name=\"4\"></a>\n",
    "<hr>\n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Carry out feature engineering. In other words, extract new features relevant for the problem and work with your new feature set in the following exercises. You may have to go back and forth between feature engineering and preprocessing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_4\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. I'm creating features that represent the differences in payments made and owed payments because it is possible that people who pay less than the amount they owe are likely to eventually default on their payments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "      <th>DIFF_1</th>\n",
       "      <th>DIFF_2</th>\n",
       "      <th>DIFF_3</th>\n",
       "      <th>DIFF_4</th>\n",
       "      <th>DIFF_5</th>\n",
       "      <th>DIFF_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25665</th>\n",
       "      <td>25666</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>22373.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>27691.0</td>\n",
       "      <td>23391.0</td>\n",
       "      <td>13600.0</td>\n",
       "      <td>-22373.0</td>\n",
       "      <td>43344.0</td>\n",
       "      <td>8697.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16464</th>\n",
       "      <td>16465</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1603.0</td>\n",
       "      <td>1903.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>0</td>\n",
       "      <td>72450.0</td>\n",
       "      <td>67967.0</td>\n",
       "      <td>51169.0</td>\n",
       "      <td>49272.0</td>\n",
       "      <td>48469.0</td>\n",
       "      <td>47464.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22386</th>\n",
       "      <td>22387</td>\n",
       "      <td>170000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>13000.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>149110.0</td>\n",
       "      <td>152319.0</td>\n",
       "      <td>161487.0</td>\n",
       "      <td>144577.0</td>\n",
       "      <td>162594.0</td>\n",
       "      <td>169922.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10149</th>\n",
       "      <td>10150</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22828.0</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8729</th>\n",
       "      <td>8730</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>341.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7074.0</td>\n",
       "      <td>6884.0</td>\n",
       "      <td>8713.0</td>\n",
       "      <td>8884.0</td>\n",
       "      <td>9061.0</td>\n",
       "      <td>9287.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17548</th>\n",
       "      <td>17549</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>600.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>48806.0</td>\n",
       "      <td>48880.0</td>\n",
       "      <td>50474.0</td>\n",
       "      <td>51208.0</td>\n",
       "      <td>15941.0</td>\n",
       "      <td>16295.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11459</th>\n",
       "      <td>11460</td>\n",
       "      <td>310000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>2505.0</td>\n",
       "      <td>816.0</td>\n",
       "      <td>3052.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2252.0</td>\n",
       "      <td>631.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>-501.0</td>\n",
       "      <td>1687.0</td>\n",
       "      <td>-2238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6608</th>\n",
       "      <td>6609</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1535.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4680.0</td>\n",
       "      <td>5862.0</td>\n",
       "      <td>7144.0</td>\n",
       "      <td>7326.0</td>\n",
       "      <td>10104.0</td>\n",
       "      <td>8803.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2414</th>\n",
       "      <td>2415</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2281.0</td>\n",
       "      <td>-1385.0</td>\n",
       "      <td>953.0</td>\n",
       "      <td>2713.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14757</th>\n",
       "      <td>14758</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>25390.0</td>\n",
       "      <td>28190.0</td>\n",
       "      <td>29058.0</td>\n",
       "      <td>28599.0</td>\n",
       "      <td>25956.0</td>\n",
       "      <td>28484.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9000 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  \\\n",
       "25665  25666    40000.0    2          2         2   26     -1      0      0   \n",
       "16464  16465    80000.0    2          3         1   59      0      0      0   \n",
       "22386  22387   170000.0    2          1         2   30      2      2      2   \n",
       "10149  10150   200000.0    2          2         1   41     -2     -2     -2   \n",
       "8729    8730    50000.0    1          2         1   43      0      0      0   \n",
       "...      ...        ...  ...        ...       ...  ...    ...    ...    ...   \n",
       "17548  17549    60000.0    2          2         1   48      0      0      0   \n",
       "11459  11460   310000.0    1          2         1   43     -1     -1     -1   \n",
       "6608    6609    10000.0    2          2         2   22      0      0      0   \n",
       "2414    2415    30000.0    1          2         1   38      1     -1     -1   \n",
       "14757  14758    30000.0    2          3         1   24      2      0      0   \n",
       "\n",
       "       PAY_4  ...  PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \\\n",
       "25665      0  ...   22373.0     680.0   10000.0                           0   \n",
       "16464      0  ...    1603.0    1903.0    2006.0                           0   \n",
       "22386      2  ...   13000.0    5500.0    1000.0                           1   \n",
       "10149     -2  ...       0.0       0.0       0.0                           1   \n",
       "8729       0  ...     341.0     356.0     330.0                           0   \n",
       "...      ...  ...       ...       ...       ...                         ...   \n",
       "17548      0  ...     600.0    1000.0    1000.0                           1   \n",
       "11459     -1  ...    2505.0     816.0    3052.0                           0   \n",
       "6608       0  ...    1535.0       0.0    1000.0                           0   \n",
       "2414      -1  ...       0.0       0.0       0.0                           1   \n",
       "14757      0  ...    1022.0    2000.0    1000.0                           0   \n",
       "\n",
       "         DIFF_1    DIFF_2    DIFF_3    DIFF_4    DIFF_5    DIFF_6  \n",
       "25665   27691.0   23391.0   13600.0  -22373.0   43344.0    8697.0  \n",
       "16464   72450.0   67967.0   51169.0   49272.0   48469.0   47464.0  \n",
       "22386  149110.0  152319.0  161487.0  144577.0  162594.0  169922.0  \n",
       "10149   22828.0     735.0       0.0       0.0       0.0       0.0  \n",
       "8729     7074.0    6884.0    8713.0    8884.0    9061.0    9287.0  \n",
       "...         ...       ...       ...       ...       ...       ...  \n",
       "17548   48806.0   48880.0   50474.0   51208.0   15941.0   16295.0  \n",
       "11459    2252.0     631.0      42.0    -501.0    1687.0   -2238.0  \n",
       "6608     4680.0    5862.0    7144.0    7326.0   10104.0    8803.0  \n",
       "2414    -2281.0   -1385.0     953.0    2713.0       0.0       0.0  \n",
       "14757   25390.0   28190.0   29058.0   28599.0   25956.0   28484.0  \n",
       "\n",
       "[9000 rows x 31 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.assign(DIFF_1 = train_df[\"BILL_AMT1\"] - train_df[\"PAY_AMT1\"])\n",
    "train_df = train_df.assign(DIFF_2 = train_df[\"BILL_AMT2\"] - train_df[\"PAY_AMT2\"])\n",
    "train_df = train_df.assign(DIFF_3 = train_df[\"BILL_AMT3\"] - train_df[\"PAY_AMT3\"])\n",
    "train_df = train_df.assign(DIFF_4 = train_df[\"BILL_AMT4\"] - train_df[\"PAY_AMT4\"])\n",
    "train_df = train_df.assign(DIFF_5 = train_df[\"BILL_AMT5\"] - train_df[\"PAY_AMT5\"])\n",
    "train_df = train_df.assign(DIFF_6 = train_df[\"BILL_AMT6\"] - train_df[\"PAY_AMT6\"])\n",
    "train_df\n",
    "\n",
    "test_df = test_df.assign(DIFF_1 = test_df[\"BILL_AMT1\"] - test_df[\"PAY_AMT1\"])\n",
    "test_df = test_df.assign(DIFF_2 = test_df[\"BILL_AMT2\"] - test_df[\"PAY_AMT2\"])\n",
    "test_df = test_df.assign(DIFF_3 = test_df[\"BILL_AMT3\"] - test_df[\"PAY_AMT3\"])\n",
    "test_df = test_df.assign(DIFF_4 = test_df[\"BILL_AMT4\"] - test_df[\"PAY_AMT4\"])\n",
    "test_df = test_df.assign(DIFF_5 = test_df[\"BILL_AMT5\"] - test_df[\"PAY_AMT5\"])\n",
    "test_df = test_df.assign(DIFF_6 = test_df[\"BILL_AMT6\"] - test_df[\"PAY_AMT6\"])\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 5. Preprocessing and transformations <a name=\"5\"></a>\n",
    "<hr>\n",
    "rubric={points:10}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Identify different feature types and the transformations you would apply on each feature type. \n",
    "2. Define a column transformer, if necessary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_5\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "1.\n",
    "- All the features are already numerical.\n",
    "- Due to the lack of relevance, we can drop the ID column.\n",
    "- We should apply standard scaling to all the numeric non-categorical columns.\n",
    "- Education and marriage should be encoded with OHE instead since their ordinality doesn't make the most sense.\n",
    "- Sex should be encoded with binary OHE instead since it only has 2 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=\"default.payment.next.month\")\n",
    "y_train = train_df[\"default.payment.next.month\"]\n",
    "X_test = test_df.drop(columns=\"default.payment.next.month\")\n",
    "y_test = test_df[\"default.payment.next.month\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_fts = [\"LIMIT_BAL\", \"AGE\", \n",
    "               \"DIFF_1\", \"DIFF_2\", \"DIFF_3\", \"DIFF_4\", \"DIFF_5\", \"DIFF_6\",\n",
    "               \"BILL_AMT1\", \"BILL_AMT2\", \"BILL_AMT3\", \"BILL_AMT4\", \"BILL_AMT5\", \"BILL_AMT6\", \n",
    "               \"PAY_AMT1\", \"PAY_AMT2\", \"PAY_AMT3\", \"PAY_AMT4\", \"PAY_AMT5\", \"PAY_AMT6\", \n",
    "               \"PAY_0\", \"PAY_2\", \"PAY_3\", \"PAY_4\", \"PAY_5\", \"PAY_6\"]\n",
    "ohe_fts = [\"EDUCATION\", \"MARRIAGE\"]\n",
    "bin_fts = [\"SEX\"]\n",
    "drop_fts = [\"ID\"]\n",
    "ct = make_column_transformer(\n",
    "    (StandardScaler(), num_fts),\n",
    "    (OneHotEncoder(sparse=\"false\", handle_unknown=\"ignore\"), ohe_fts),\n",
    "    (OneHotEncoder(drop=\"if_binary\", sparse=\"false\"), bin_fts),\n",
    "    (\"drop\", drop_fts)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 6. Baseline model <a name=\"6\"></a>\n",
    "<hr>\n",
    "rubric={points:2}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Try `scikit-learn`'s baseline model and report results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_6\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       0.002986\n",
       "score_time     0.000074\n",
       "test_score     0.776762\n",
       "train_score    0.776762\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = DummyClassifier()\n",
    "pd.DataFrame(cross_validate(dummy, X_train, y_train, return_train_score=True)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77690476, 0.77690476, 0.77666667, 0.77666667, 0.77666667])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(dummy, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline model scores exactly the percentage of the most frequent class, which is 0, as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 7. Linear models <a name=\"7\"></a>\n",
    "<hr>\n",
    "rubric={points:10}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Try a linear model as a first real attempt. \n",
    "2. Carry out hyperparameter tuning to explore different values for the complexity hyperparameter. \n",
    "3. Report cross-validation scores along with standard deviation. \n",
    "4. Summarize your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_7\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>mean_train_accuracy</th>\n",
       "      <th>mean_cv_accuracy</th>\n",
       "      <th>mean_train_f1</th>\n",
       "      <th>mean_cv_f1</th>\n",
       "      <th>std_train_accuracy</th>\n",
       "      <th>std_cv_accuracy</th>\n",
       "      <th>std_train_f1</th>\n",
       "      <th>std_cv_f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.778905</td>\n",
       "      <td>0.778810</td>\n",
       "      <td>0.687622</td>\n",
       "      <td>0.687442</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>0.778810</td>\n",
       "      <td>0.757178</td>\n",
       "      <td>0.033520</td>\n",
       "      <td>0.011210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.800571</td>\n",
       "      <td>0.800667</td>\n",
       "      <td>0.747737</td>\n",
       "      <td>0.747994</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>0.001642</td>\n",
       "      <td>0.005254</td>\n",
       "      <td>0.800667</td>\n",
       "      <td>0.788529</td>\n",
       "      <td>0.037834</td>\n",
       "      <td>0.011210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.809155</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.768596</td>\n",
       "      <td>0.767403</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>0.002409</td>\n",
       "      <td>0.003613</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.794102</td>\n",
       "      <td>0.057801</td>\n",
       "      <td>0.010279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.810905</td>\n",
       "      <td>0.810238</td>\n",
       "      <td>0.772567</td>\n",
       "      <td>0.771968</td>\n",
       "      <td>0.001290</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.002824</td>\n",
       "      <td>0.810238</td>\n",
       "      <td>0.795750</td>\n",
       "      <td>0.109101</td>\n",
       "      <td>0.010110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.811214</td>\n",
       "      <td>0.810476</td>\n",
       "      <td>0.773159</td>\n",
       "      <td>0.772513</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>0.001763</td>\n",
       "      <td>0.002292</td>\n",
       "      <td>0.002815</td>\n",
       "      <td>0.810476</td>\n",
       "      <td>0.795987</td>\n",
       "      <td>0.240230</td>\n",
       "      <td>0.010013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.0000</td>\n",
       "      <td>0.811262</td>\n",
       "      <td>0.810571</td>\n",
       "      <td>0.773245</td>\n",
       "      <td>0.772628</td>\n",
       "      <td>0.001346</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.002431</td>\n",
       "      <td>0.002599</td>\n",
       "      <td>0.810571</td>\n",
       "      <td>0.796174</td>\n",
       "      <td>0.230061</td>\n",
       "      <td>0.011175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100.0000</td>\n",
       "      <td>0.811262</td>\n",
       "      <td>0.810571</td>\n",
       "      <td>0.773245</td>\n",
       "      <td>0.772670</td>\n",
       "      <td>0.001357</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.002442</td>\n",
       "      <td>0.002522</td>\n",
       "      <td>0.810571</td>\n",
       "      <td>0.796135</td>\n",
       "      <td>0.220529</td>\n",
       "      <td>0.010209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000.0000</td>\n",
       "      <td>0.811250</td>\n",
       "      <td>0.810571</td>\n",
       "      <td>0.773236</td>\n",
       "      <td>0.772670</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.002522</td>\n",
       "      <td>0.810571</td>\n",
       "      <td>0.796135</td>\n",
       "      <td>0.284754</td>\n",
       "      <td>0.010408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10000.0000</td>\n",
       "      <td>0.811286</td>\n",
       "      <td>0.810571</td>\n",
       "      <td>0.773274</td>\n",
       "      <td>0.772670</td>\n",
       "      <td>0.001343</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.002417</td>\n",
       "      <td>0.002522</td>\n",
       "      <td>0.810571</td>\n",
       "      <td>0.796135</td>\n",
       "      <td>0.218579</td>\n",
       "      <td>0.009208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100000.0000</td>\n",
       "      <td>0.811262</td>\n",
       "      <td>0.810571</td>\n",
       "      <td>0.773245</td>\n",
       "      <td>0.772670</td>\n",
       "      <td>0.001329</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.002398</td>\n",
       "      <td>0.002522</td>\n",
       "      <td>0.810571</td>\n",
       "      <td>0.796135</td>\n",
       "      <td>0.209032</td>\n",
       "      <td>0.009409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             C  mean_train_accuracy  mean_cv_accuracy  mean_train_f1  \\\n",
       "0       0.0001             0.778905          0.778810       0.687622   \n",
       "1       0.0010             0.800571          0.800667       0.747737   \n",
       "2       0.0100             0.809155          0.808333       0.768596   \n",
       "3       0.1000             0.810905          0.810238       0.772567   \n",
       "4       1.0000             0.811214          0.810476       0.773159   \n",
       "5      10.0000             0.811262          0.810571       0.773245   \n",
       "6     100.0000             0.811262          0.810571       0.773245   \n",
       "7    1000.0000             0.811250          0.810571       0.773236   \n",
       "8   10000.0000             0.811286          0.810571       0.773274   \n",
       "9  100000.0000             0.811262          0.810571       0.773245   \n",
       "\n",
       "   mean_cv_f1  std_train_accuracy  std_cv_accuracy  std_train_f1  std_cv_f1  \\\n",
       "0    0.687442            0.000144         0.000782      0.000212   0.001307   \n",
       "1    0.747994            0.000831         0.002823      0.001642   0.005254   \n",
       "2    0.767403            0.001283         0.002003      0.002409   0.003613   \n",
       "3    0.771968            0.001290         0.001724      0.002326   0.002824   \n",
       "4    0.772513            0.001256         0.001763      0.002292   0.002815   \n",
       "5    0.772628            0.001346         0.001626      0.002431   0.002599   \n",
       "6    0.772670            0.001357         0.001626      0.002442   0.002522   \n",
       "7    0.772670            0.001366         0.001626      0.002445   0.002522   \n",
       "8    0.772670            0.001343         0.001626      0.002417   0.002522   \n",
       "9    0.772670            0.001329         0.001626      0.002398   0.002522   \n",
       "\n",
       "     recall  precision  mean_fit_time  mean_score_time  \n",
       "0  0.778810   0.757178       0.033520         0.011210  \n",
       "1  0.800667   0.788529       0.037834         0.011210  \n",
       "2  0.808333   0.794102       0.057801         0.010279  \n",
       "3  0.810238   0.795750       0.109101         0.010110  \n",
       "4  0.810476   0.795987       0.240230         0.010013  \n",
       "5  0.810571   0.796174       0.230061         0.011175  \n",
       "6  0.810571   0.796135       0.220529         0.010209  \n",
       "7  0.810571   0.796135       0.284754         0.010408  \n",
       "8  0.810571   0.796135       0.218579         0.009208  \n",
       "9  0.810571   0.796135       0.209032         0.009409  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring_metrics = {\n",
    "    \"accuracy\": \"accuracy\",\n",
    "    \"recall\": \"recall_weighted\",\n",
    "    \"precision\": \"precision_weighted\",\n",
    "    \"f1\": \"f1_weighted\"\n",
    "}\n",
    "\n",
    "scoring = {\n",
    "    \"C\": 10.0 ** np.arange(-4, 6, 1),\n",
    "    \n",
    "    \"mean_train_accuracy\": list(),\n",
    "    \"mean_cv_accuracy\": list(),\n",
    "    \"mean_train_f1\": list(),\n",
    "    \"mean_cv_f1\": list(),\n",
    "    \n",
    "    \"std_train_accuracy\": list(),\n",
    "    \"std_cv_accuracy\": list(),\n",
    "    \"std_train_f1\": list(),\n",
    "    \"std_cv_f1\": list(),\n",
    "    \n",
    "    \"recall\": list(),\n",
    "    \"precision\": list(),\n",
    "    \n",
    "    \"mean_fit_time\": list(),\n",
    "    \"mean_score_time\": list(),\n",
    "}\n",
    "\n",
    "for C in scoring[\"C\"]:\n",
    "    pipe_log = make_pipeline(ct, LogisticRegression(C=C, max_iter=500))\n",
    "    scores = cross_validate(pipe_log, X_train, y_train, return_train_score=True, scoring=scoring_metrics)\n",
    "    \n",
    "    scoring[\"mean_train_accuracy\"].append(scores[\"train_accuracy\"].mean())\n",
    "    scoring[\"mean_cv_accuracy\"].append(scores[\"test_accuracy\"].mean())\n",
    "    scoring[\"mean_train_f1\"].append(scores[\"train_f1\"].mean())\n",
    "    scoring[\"mean_cv_f1\"].append(scores[\"test_f1\"].mean())\n",
    "    \n",
    "    scoring[\"std_train_accuracy\"].append(scores[\"train_accuracy\"].std())\n",
    "    scoring[\"std_cv_accuracy\"].append(scores[\"test_accuracy\"].std())\n",
    "    scoring[\"std_train_f1\"].append(scores[\"train_f1\"].std())\n",
    "    scoring[\"std_cv_f1\"].append(scores[\"test_f1\"].std())\n",
    "    \n",
    "    scoring[\"recall\"].append(scores[\"test_recall\"].mean())\n",
    "    scoring[\"precision\"].append(scores[\"test_precision\"].mean())\n",
    "    \n",
    "    scoring[\"mean_fit_time\"].append(scores[\"fit_time\"].mean())\n",
    "    scoring[\"mean_score_time\"].append(scores[\"score_time\"].mean())\n",
    "\n",
    "results_df = pd.DataFrame(scoring)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "C = 10.0 seems to be the best hyperparameter value because it has the highest cross validation, recall, and precision scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 8. Different models <a name=\"8\"></a>\n",
    "<hr>\n",
    "rubric={points:12}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Try at least 3 other models aside from a linear model. One of these models should be a tree-based ensemble model. \n",
    "2. Summarize your results in terms of overfitting/underfitting and fit and score times. Can you beat a linear model? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_8\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scoring = {\n",
    "    \n",
    "    \"mean_train_accuracy\": list(),\n",
    "    \"mean_cv_accuracy\": list(),\n",
    "    \"mean_train_f1\": list(),\n",
    "    \"mean_cv_f1\": list(),\n",
    "    \n",
    "    \"std_train_accuracy\": list(),\n",
    "    \"std_cv_accuracy\": list(),\n",
    "    \"std_train_f1\": list(),\n",
    "    \"std_cv_f1\": list(),\n",
    "    \n",
    "    \"recall\": list(),\n",
    "    \"precision\": list(),\n",
    "    \n",
    "    \"mean_fit_time\": list(),\n",
    "    \"mean_score_time\": list(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_accuracy</th>\n",
       "      <th>mean_cv_accuracy</th>\n",
       "      <th>mean_train_f1</th>\n",
       "      <th>mean_cv_f1</th>\n",
       "      <th>std_train_accuracy</th>\n",
       "      <th>std_cv_accuracy</th>\n",
       "      <th>std_train_f1</th>\n",
       "      <th>std_cv_f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999381</td>\n",
       "      <td>0.813762</td>\n",
       "      <td>0.999381</td>\n",
       "      <td>0.794044</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.004059</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.003555</td>\n",
       "      <td>0.813762</td>\n",
       "      <td>0.795443</td>\n",
       "      <td>1.299752</td>\n",
       "      <td>0.040237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_train_accuracy  mean_cv_accuracy  mean_train_f1  mean_cv_f1  \\\n",
       "0             0.999381          0.813762       0.999381    0.794044   \n",
       "\n",
       "   std_train_accuracy  std_cv_accuracy  std_train_f1  std_cv_f1    recall  \\\n",
       "0             0.00011         0.004059       0.00011   0.003555  0.813762   \n",
       "\n",
       "   precision  mean_fit_time  mean_score_time  \n",
       "0   0.795443       1.299752         0.040237  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_log = make_pipeline(ct, RandomForestClassifier(random_state=123, n_jobs=-1))\n",
    "scores = cross_validate(pipe_log, X_train, y_train, return_train_score=True, scoring=scoring_metrics)\n",
    "\n",
    "scoring[\"mean_train_accuracy\"].append(scores[\"train_accuracy\"].mean())\n",
    "scoring[\"mean_cv_accuracy\"].append(scores[\"test_accuracy\"].mean())\n",
    "scoring[\"mean_train_f1\"].append(scores[\"train_f1\"].mean())\n",
    "scoring[\"mean_cv_f1\"].append(scores[\"test_f1\"].mean())\n",
    "\n",
    "scoring[\"std_train_accuracy\"].append(scores[\"train_accuracy\"].std())\n",
    "scoring[\"std_cv_accuracy\"].append(scores[\"test_accuracy\"].std())\n",
    "scoring[\"std_train_f1\"].append(scores[\"train_f1\"].std())\n",
    "scoring[\"std_cv_f1\"].append(scores[\"test_f1\"].std())\n",
    "\n",
    "scoring[\"recall\"].append(scores[\"test_recall\"].mean())\n",
    "scoring[\"precision\"].append(scores[\"test_precision\"].mean())\n",
    "\n",
    "scoring[\"mean_fit_time\"].append(scores[\"fit_time\"].mean())\n",
    "scoring[\"mean_score_time\"].append(scores[\"score_time\"].mean())\n",
    "\n",
    "results_df = pd.DataFrame(scoring)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_accuracy</th>\n",
       "      <th>mean_cv_accuracy</th>\n",
       "      <th>mean_train_f1</th>\n",
       "      <th>mean_cv_f1</th>\n",
       "      <th>std_train_accuracy</th>\n",
       "      <th>std_cv_accuracy</th>\n",
       "      <th>std_train_f1</th>\n",
       "      <th>std_cv_f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999381</td>\n",
       "      <td>0.813762</td>\n",
       "      <td>0.999381</td>\n",
       "      <td>0.794044</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.004059</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.003555</td>\n",
       "      <td>0.813762</td>\n",
       "      <td>0.795443</td>\n",
       "      <td>1.299752</td>\n",
       "      <td>0.040237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.808905</td>\n",
       "      <td>0.809000</td>\n",
       "      <td>0.770987</td>\n",
       "      <td>0.770881</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>0.003358</td>\n",
       "      <td>0.00176</td>\n",
       "      <td>0.004486</td>\n",
       "      <td>0.809000</td>\n",
       "      <td>0.793095</td>\n",
       "      <td>15.894899</td>\n",
       "      <td>0.705485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_train_accuracy  mean_cv_accuracy  mean_train_f1  mean_cv_f1  \\\n",
       "0             0.999381          0.813762       0.999381    0.794044   \n",
       "1             0.808905          0.809000       0.770987    0.770881   \n",
       "\n",
       "   std_train_accuracy  std_cv_accuracy  std_train_f1  std_cv_f1    recall  \\\n",
       "0            0.000110         0.004059       0.00011   0.003555  0.813762   \n",
       "1            0.000864         0.003358       0.00176   0.004486  0.809000   \n",
       "\n",
       "   precision  mean_fit_time  mean_score_time  \n",
       "0   0.795443       1.299752         0.040237  \n",
       "1   0.793095      15.894899         0.705485  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "pipe_log = make_pipeline(ct, SVC(kernel=\"linear\"))\n",
    "scores = cross_validate(pipe_log, X_train, y_train, return_train_score=True, scoring=scoring_metrics)\n",
    "\n",
    "scoring[\"mean_train_accuracy\"].append(scores[\"train_accuracy\"].mean())\n",
    "scoring[\"mean_cv_accuracy\"].append(scores[\"test_accuracy\"].mean())\n",
    "scoring[\"mean_train_f1\"].append(scores[\"train_f1\"].mean())\n",
    "scoring[\"mean_cv_f1\"].append(scores[\"test_f1\"].mean())\n",
    "\n",
    "scoring[\"std_train_accuracy\"].append(scores[\"train_accuracy\"].std())\n",
    "scoring[\"std_cv_accuracy\"].append(scores[\"test_accuracy\"].std())\n",
    "scoring[\"std_train_f1\"].append(scores[\"train_f1\"].std())\n",
    "scoring[\"std_cv_f1\"].append(scores[\"test_f1\"].std())\n",
    "\n",
    "scoring[\"recall\"].append(scores[\"test_recall\"].mean())\n",
    "scoring[\"precision\"].append(scores[\"test_precision\"].mean())\n",
    "\n",
    "scoring[\"mean_fit_time\"].append(scores[\"fit_time\"].mean())\n",
    "scoring[\"mean_score_time\"].append(scores[\"score_time\"].mean())\n",
    "\n",
    "results_df = pd.DataFrame(scoring)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_accuracy</th>\n",
       "      <th>mean_cv_accuracy</th>\n",
       "      <th>mean_train_f1</th>\n",
       "      <th>mean_cv_f1</th>\n",
       "      <th>std_train_accuracy</th>\n",
       "      <th>std_cv_accuracy</th>\n",
       "      <th>std_train_f1</th>\n",
       "      <th>std_cv_f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999381</td>\n",
       "      <td>0.813762</td>\n",
       "      <td>0.999381</td>\n",
       "      <td>0.794044</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.004059</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.003555</td>\n",
       "      <td>0.813762</td>\n",
       "      <td>0.795443</td>\n",
       "      <td>1.299752</td>\n",
       "      <td>0.040237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.808905</td>\n",
       "      <td>0.809000</td>\n",
       "      <td>0.770987</td>\n",
       "      <td>0.770881</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>0.003358</td>\n",
       "      <td>0.00176</td>\n",
       "      <td>0.004486</td>\n",
       "      <td>0.809000</td>\n",
       "      <td>0.793095</td>\n",
       "      <td>15.894899</td>\n",
       "      <td>0.705485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.999405</td>\n",
       "      <td>0.723714</td>\n",
       "      <td>0.999404</td>\n",
       "      <td>0.727794</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.007642</td>\n",
       "      <td>0.723714</td>\n",
       "      <td>0.732536</td>\n",
       "      <td>0.401643</td>\n",
       "      <td>0.008809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_train_accuracy  mean_cv_accuracy  mean_train_f1  mean_cv_f1  \\\n",
       "0             0.999381          0.813762       0.999381    0.794044   \n",
       "1             0.808905          0.809000       0.770987    0.770881   \n",
       "2             0.999405          0.723714       0.999404    0.727794   \n",
       "\n",
       "   std_train_accuracy  std_cv_accuracy  std_train_f1  std_cv_f1    recall  \\\n",
       "0            0.000110         0.004059       0.00011   0.003555  0.813762   \n",
       "1            0.000864         0.003358       0.00176   0.004486  0.809000   \n",
       "2            0.000100         0.008797       0.00010   0.007642  0.723714   \n",
       "\n",
       "   precision  mean_fit_time  mean_score_time  \n",
       "0   0.795443       1.299752         0.040237  \n",
       "1   0.793095      15.894899         0.705485  \n",
       "2   0.732536       0.401643         0.008809  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pipe_log = make_pipeline(ct, DecisionTreeClassifier())\n",
    "scores = cross_validate(pipe_log, X_train, y_train, return_train_score=True, scoring=scoring_metrics)\n",
    "\n",
    "scoring[\"mean_train_accuracy\"].append(scores[\"train_accuracy\"].mean())\n",
    "scoring[\"mean_cv_accuracy\"].append(scores[\"test_accuracy\"].mean())\n",
    "scoring[\"mean_train_f1\"].append(scores[\"train_f1\"].mean())\n",
    "scoring[\"mean_cv_f1\"].append(scores[\"test_f1\"].mean())\n",
    "\n",
    "scoring[\"std_train_accuracy\"].append(scores[\"train_accuracy\"].std())\n",
    "scoring[\"std_cv_accuracy\"].append(scores[\"test_accuracy\"].std())\n",
    "scoring[\"std_train_f1\"].append(scores[\"train_f1\"].std())\n",
    "scoring[\"std_cv_f1\"].append(scores[\"test_f1\"].std())\n",
    "\n",
    "scoring[\"recall\"].append(scores[\"test_recall\"].mean())\n",
    "scoring[\"precision\"].append(scores[\"test_precision\"].mean())\n",
    "\n",
    "scoring[\"mean_fit_time\"].append(scores[\"fit_time\"].mean())\n",
    "scoring[\"mean_score_time\"].append(scores[\"score_time\"].mean())\n",
    "\n",
    "results_df = pd.DataFrame(scoring)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Decision tree and random forests look clearly overfitted with their near perfect train accuracy and low validation accuracy.  Linear SVC is very similar to the logistic regression model, and both seem underfitted due to their lower training accuracy and near matching validation accuracy.  In terms of time, decision tree was very fast due to its simplicity, followed by logical regression, then random forests, and lastly linear SVM was far slower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## (Optional) 9. Feature selection <a name=\"9\"></a>\n",
    "<hr>\n",
    "rubric={points:2}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Make some attempts to select relevant features. You may try `RFECV` or forward selection for this. Do the results improve with feature selection? Summarize your results. If you see improvements in the results, keep feature selection in your pipeline. If not, you may abandon it in the next exercises. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_9\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_accuracy</th>\n",
       "      <th>mean_cv_accuracy</th>\n",
       "      <th>mean_train_f1</th>\n",
       "      <th>mean_cv_f1</th>\n",
       "      <th>std_train_accuracy</th>\n",
       "      <th>std_cv_accuracy</th>\n",
       "      <th>std_train_f1</th>\n",
       "      <th>std_cv_f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999381</td>\n",
       "      <td>0.813762</td>\n",
       "      <td>0.999381</td>\n",
       "      <td>0.794044</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.004059</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.003555</td>\n",
       "      <td>0.813762</td>\n",
       "      <td>0.795443</td>\n",
       "      <td>1.299752</td>\n",
       "      <td>0.040237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.808905</td>\n",
       "      <td>0.809000</td>\n",
       "      <td>0.770987</td>\n",
       "      <td>0.770881</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>0.003358</td>\n",
       "      <td>0.001760</td>\n",
       "      <td>0.004486</td>\n",
       "      <td>0.809000</td>\n",
       "      <td>0.793095</td>\n",
       "      <td>15.894899</td>\n",
       "      <td>0.705485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.999405</td>\n",
       "      <td>0.723714</td>\n",
       "      <td>0.999404</td>\n",
       "      <td>0.727794</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.007642</td>\n",
       "      <td>0.723714</td>\n",
       "      <td>0.732536</td>\n",
       "      <td>0.401643</td>\n",
       "      <td>0.008809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.818845</td>\n",
       "      <td>0.818762</td>\n",
       "      <td>0.791988</td>\n",
       "      <td>0.791877</td>\n",
       "      <td>0.001232</td>\n",
       "      <td>0.005094</td>\n",
       "      <td>0.001417</td>\n",
       "      <td>0.005732</td>\n",
       "      <td>0.818762</td>\n",
       "      <td>0.803463</td>\n",
       "      <td>29.263350</td>\n",
       "      <td>0.009008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_train_accuracy  mean_cv_accuracy  mean_train_f1  mean_cv_f1  \\\n",
       "0             0.999381          0.813762       0.999381    0.794044   \n",
       "1             0.808905          0.809000       0.770987    0.770881   \n",
       "2             0.999405          0.723714       0.999404    0.727794   \n",
       "3             0.818845          0.818762       0.791988    0.791877   \n",
       "\n",
       "   std_train_accuracy  std_cv_accuracy  std_train_f1  std_cv_f1    recall  \\\n",
       "0            0.000110         0.004059      0.000110   0.003555  0.813762   \n",
       "1            0.000864         0.003358      0.001760   0.004486  0.809000   \n",
       "2            0.000100         0.008797      0.000100   0.007642  0.723714   \n",
       "3            0.001232         0.005094      0.001417   0.005732  0.818762   \n",
       "\n",
       "   precision  mean_fit_time  mean_score_time  \n",
       "0   0.795443       1.299752         0.040237  \n",
       "1   0.793095      15.894899         0.705485  \n",
       "2   0.732536       0.401643         0.008809  \n",
       "3   0.803463      29.263350         0.009008  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "rfe_cv = RFECV(LogisticRegression(max_iter=2000), cv=10)\n",
    "rfe_cv\n",
    "\n",
    "pipe_log = make_pipeline(ct, rfe_cv)\n",
    "scores = cross_validate(pipe_log, X_train, y_train, return_train_score=True, scoring=scoring_metrics)\n",
    "\n",
    "scoring[\"mean_train_accuracy\"].append(scores[\"train_accuracy\"].mean())\n",
    "scoring[\"mean_cv_accuracy\"].append(scores[\"test_accuracy\"].mean())\n",
    "scoring[\"mean_train_f1\"].append(scores[\"train_f1\"].mean())\n",
    "scoring[\"mean_cv_f1\"].append(scores[\"test_f1\"].mean())\n",
    "\n",
    "scoring[\"std_train_accuracy\"].append(scores[\"train_accuracy\"].std())\n",
    "scoring[\"std_cv_accuracy\"].append(scores[\"test_accuracy\"].std())\n",
    "scoring[\"std_train_f1\"].append(scores[\"train_f1\"].std())\n",
    "scoring[\"std_cv_f1\"].append(scores[\"test_f1\"].std())\n",
    "\n",
    "scoring[\"recall\"].append(scores[\"test_recall\"].mean())\n",
    "scoring[\"precision\"].append(scores[\"test_precision\"].mean())\n",
    "\n",
    "scoring[\"mean_fit_time\"].append(scores[\"fit_time\"].mean())\n",
    "scoring[\"mean_score_time\"].append(scores[\"score_time\"].mean())\n",
    "\n",
    "results_df = pd.DataFrame(scoring)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The scores increased slightly, by around 1% each, but the change seems insignificant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 10. Hyperparameter optimization <a name=\"10\"></a>\n",
    "<hr>\n",
    "rubric={points:10}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Make some attempts to optimize hyperparameters for the models you've tried and summarize your results. In at least one case you should be optimizing multiple hyperparameters for a single model. You may use `sklearn`'s methods for hyperparameter optimization or fancier Bayesian optimization methods. \n",
    "  - [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)   \n",
    "  - [RandomizedSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "  - [scikit-optimize](https://github.com/scikit-optimize/scikit-optimize) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_10\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>mean_cv_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.813762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.813762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.813762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.813762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.813762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.813762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.813762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.813762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.813762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.813762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.813762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.813762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.813762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.813762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.813762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.813762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_estimators  max_depth  mean_cv_score\n",
       "0              1          1       0.813762\n",
       "1              5          1       0.813762\n",
       "2             10          1       0.813762\n",
       "3             20          1       0.813762\n",
       "4              1          5       0.813762\n",
       "5              5          5       0.813762\n",
       "6             10          5       0.813762\n",
       "7             20          5       0.813762\n",
       "8              1         10       0.813762\n",
       "9              5         10       0.813762\n",
       "10            10         10       0.813762\n",
       "11            20         10       0.813762\n",
       "12             1         20       0.813762\n",
       "13             5         20       0.813762\n",
       "14            10         20       0.813762\n",
       "15            20         20       0.813762"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": [1, 5, 10, 20],\n",
    "    \"max_depth\": [1, 5, 10, 20],\n",
    "}\n",
    "\n",
    "results_dict = {\"n_estimators\": [], \"max_depth\": [], \"mean_cv_score\": []}\n",
    "\n",
    "for max_depth in param_grid[\"max_depth\"]:\n",
    "    for n_estimators in param_grid[\"n_estimators\"]:\n",
    "        pipe = make_pipeline(ct, RandomForestClassifier(random_state=123, n_jobs=-1))\n",
    "        scores = cross_val_score(pipe, X_train, y_train)\n",
    "        mean_score = np.mean(scores)\n",
    "        results_dict[\"n_estimators\"].append(n_estimators)\n",
    "        results_dict[\"max_depth\"].append(max_depth)\n",
    "        results_dict[\"mean_cv_score\"].append(mean_score)\n",
    "pd.DataFrame(results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Random forest hyperparameters don't seem to affect the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>mean_cv_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.818381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.819095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.817238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0.813762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0.809238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>0.801095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>0.788619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15</td>\n",
       "      <td>0.776762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17</td>\n",
       "      <td>0.766381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19</td>\n",
       "      <td>0.753714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth  mean_cv_score\n",
       "0          1       0.818381\n",
       "1          3       0.819095\n",
       "2          5       0.817238\n",
       "3          7       0.813762\n",
       "4          9       0.809238\n",
       "5         11       0.801095\n",
       "6         13       0.788619\n",
       "7         15       0.776762\n",
       "8         17       0.766381\n",
       "9         19       0.753714"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score = 0\n",
    "\n",
    "param_grid = {\"max_depth\": np.arange(1, 20, 2)}\n",
    "\n",
    "results_dict = {\"max_depth\": [], \"mean_cv_score\": []}\n",
    "\n",
    "for depth in param_grid[\"max_depth\"]:\n",
    "    dt = DecisionTreeClassifier(max_depth=depth)\n",
    "    scores = cross_val_score(dt, X_train, y_train)  # perform cross-validation\n",
    "    mean_score = np.mean(scores)  # compute mean cross-validation accuracy\n",
    "    if mean_score > best_score:  # if we got a better score, store the score and parameters\n",
    "        best_score = mean_score\n",
    "        best_params = {\"max_depth\": depth}\n",
    "    results_dict[\"max_depth\"].append(depth)\n",
    "    results_dict[\"mean_cv_score\"].append(mean_score)\n",
    "pd.DataFrame(results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the cross-validation score peaks at max-depth = 1 for the DecisionTreeClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 11. Interpretation and feature importances <a name=\"1\"></a>\n",
    "<hr>\n",
    "rubric={points:10}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Use the methods we saw in class (e.g., `eli5`, `shap`) (or any other methods of your choice) to examine the most important features of one of the non-linear models. \n",
    "2. Summarize your observations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_11\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0993\n",
       "                \n",
       "                    &plusmn; 0.0935\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                PAY_0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.91%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0542\n",
       "                \n",
       "                    &plusmn; 0.0073\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                AGE\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 87.88%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0486\n",
       "                \n",
       "                    &plusmn; 0.0100\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                LIMIT_BAL\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 89.31%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0406\n",
       "                \n",
       "                    &plusmn; 0.0742\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                PAY_2\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 89.44%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0399\n",
       "                \n",
       "                    &plusmn; 0.0093\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                DIFF_1\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 89.48%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0397\n",
       "                \n",
       "                    &plusmn; 0.0081\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                BILL_AMT1\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 89.78%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0381\n",
       "                \n",
       "                    &plusmn; 0.0156\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                PAY_AMT1\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.16%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0361\n",
       "                \n",
       "                    &plusmn; 0.0092\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                DIFF_2\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.20%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0358\n",
       "                \n",
       "                    &plusmn; 0.0116\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                PAY_AMT2\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.21%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0358\n",
       "                \n",
       "                    &plusmn; 0.0099\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                DIFF_3\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.24%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0356\n",
       "                \n",
       "                    &plusmn; 0.0085\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                BILL_AMT2\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.24%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0356\n",
       "                \n",
       "                    &plusmn; 0.0081\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                DIFF_6\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.32%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0352\n",
       "                \n",
       "                    &plusmn; 0.0081\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                DIFF_5\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.49%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0343\n",
       "                \n",
       "                    &plusmn; 0.0085\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                DIFF_4\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.58%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0339\n",
       "                \n",
       "                    &plusmn; 0.0102\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                PAY_AMT3\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.64%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0336\n",
       "                \n",
       "                    &plusmn; 0.0080\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                BILL_AMT6\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.65%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0335\n",
       "                \n",
       "                    &plusmn; 0.0087\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                BILL_AMT3\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.83%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0326\n",
       "                \n",
       "                    &plusmn; 0.0089\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                BILL_AMT4\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.85%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0325\n",
       "                \n",
       "                    &plusmn; 0.0082\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                BILL_AMT5\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.89%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0323\n",
       "                \n",
       "                    &plusmn; 0.0078\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                PAY_AMT6\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.89%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 18 more &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "Explanation(estimator='RandomForestClassifier(n_jobs=-1, random_state=123)', description='\\nRandom forest feature importances; values are numbers 0 <= x <= 1;\\nall values sum to 1.\\n', error=None, method='feature importances', is_regression=False, targets=None, feature_importances=FeatureImportances(importances=[FeatureWeight(feature='PAY_0', weight=0.09931023908609381, std=0.046753424244908, value=None), FeatureWeight(feature='AGE', weight=0.05419639685671361, std=0.0036684094787987056, value=None), FeatureWeight(feature='LIMIT_BAL', weight=0.04857309646184383, std=0.005014620622531108, value=None), FeatureWeight(feature='PAY_2', weight=0.04059874379717405, std=0.03709149000824921, value=None), FeatureWeight(feature='DIFF_1', weight=0.03989939867793713, std=0.004650508222648425, value=None), FeatureWeight(feature='BILL_AMT1', weight=0.039682520106662914, std=0.004030720609842786, value=None), FeatureWeight(feature='PAY_AMT1', weight=0.0380705879682917, std=0.007815225385525105, value=None), FeatureWeight(feature='DIFF_2', weight=0.03607139104378002, std=0.004607932858527902, value=None), FeatureWeight(feature='PAY_AMT2', weight=0.03583066633424015, std=0.0058189832629116055, value=None), FeatureWeight(feature='DIFF_3', weight=0.03579455363896847, std=0.00497479097927554, value=None), FeatureWeight(feature='BILL_AMT2', weight=0.03562228116782597, std=0.004235895531610933, value=None), FeatureWeight(feature='DIFF_6', weight=0.035612235232364224, std=0.004071987709667323, value=None), FeatureWeight(feature='DIFF_5', weight=0.0352157352009104, std=0.004046374395017988, value=None), FeatureWeight(feature='DIFF_4', weight=0.03434862149269768, std=0.004228544082604656, value=None), FeatureWeight(feature='PAY_AMT3', weight=0.03387209959090491, std=0.005090342188342836, value=None), FeatureWeight(feature='BILL_AMT6', weight=0.03356380314935268, std=0.003977199828847449, value=None), FeatureWeight(feature='BILL_AMT3', weight=0.03350035139122308, std=0.004366767719056334, value=None), FeatureWeight(feature='BILL_AMT4', weight=0.03259520422494704, std=0.004463092191846561, value=None), FeatureWeight(feature='BILL_AMT5', weight=0.03249770607808193, std=0.004078460577208375, value=None), FeatureWeight(feature='PAY_AMT6', weight=0.03231274900651688, std=0.003912974952456259, value=None)], remaining=18), decision_tree=None, highlight_spaces=None, transition_features=None, image=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import eli5\n",
    "# graduate school, 2=university, 3=high school, 4=others, 5=unknown, 6=unknown\n",
    "feature_names = num_fts + [\"EDU_GRAD\", \"EDU_UNI\", \"EDU_HIGH\", \"EDU_OTHERS\", \"EDU_UNKNOWN1\", \"EDU_UNKNOWN2\", \"MARRIED\", \"SINGLE\", \"MARRIED_OTHERS\", \"MALE\", \"FEMALE\", \"ID\"]\n",
    "pipe = make_pipeline(ct, RandomForestClassifier(random_state=123, n_jobs=-1))\n",
    "pipe.fit(X_train, y_train)\n",
    "eli5 = eli5.explain_weights(\n",
    "    pipe.named_steps[\"randomforestclassifier\"], feature_names=feature_names\n",
    ")\n",
    "eli5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "2. It appears that the first repayment status, age, and balance limit are the strongest indicators of payment defaulting.  This is followed by diff, bill, and pay amounts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 12. Results on the test set <a name=\"12\"></a>\n",
    "<hr>\n",
    "\n",
    "rubric={points:10}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Try your best performing model on the test data and report test scores. \n",
    "2. Do the test scores agree with the validation scores from before? To what extent do you trust your results? Do you think you've had issues with optimization bias? \n",
    "3. Take one or two test predictions and explain these individual predictions (e.g., with SHAP force plots).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_12\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8142222222222222"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_log = make_pipeline(ct, LogisticRegression(C=10, max_iter=500))\n",
    "pipe_log.fit(X_train, y_train)\n",
    "pipe_log.predict(X_test)\n",
    "pipe_log.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "2. Yes, the test score is very close to the mean cross-validation scores previous.  There haven't been issues with optimization bias since it's very much not overfitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "      <th>DIFF_1</th>\n",
       "      <th>DIFF_2</th>\n",
       "      <th>DIFF_3</th>\n",
       "      <th>DIFF_4</th>\n",
       "      <th>DIFF_5</th>\n",
       "      <th>DIFF_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25665</th>\n",
       "      <td>25666</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>22373.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>27691.0</td>\n",
       "      <td>23391.0</td>\n",
       "      <td>13600.0</td>\n",
       "      <td>-22373.0</td>\n",
       "      <td>43344.0</td>\n",
       "      <td>8697.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16464</th>\n",
       "      <td>16465</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1603.0</td>\n",
       "      <td>1903.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>0</td>\n",
       "      <td>72450.0</td>\n",
       "      <td>67967.0</td>\n",
       "      <td>51169.0</td>\n",
       "      <td>49272.0</td>\n",
       "      <td>48469.0</td>\n",
       "      <td>47464.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22386</th>\n",
       "      <td>22387</td>\n",
       "      <td>170000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>13000.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>149110.0</td>\n",
       "      <td>152319.0</td>\n",
       "      <td>161487.0</td>\n",
       "      <td>144577.0</td>\n",
       "      <td>162594.0</td>\n",
       "      <td>169922.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  \\\n",
       "25665  25666    40000.0    2          2         2   26     -1      0      0   \n",
       "16464  16465    80000.0    2          3         1   59      0      0      0   \n",
       "22386  22387   170000.0    2          1         2   30      2      2      2   \n",
       "\n",
       "       PAY_4  ...  PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \\\n",
       "25665      0  ...   22373.0     680.0   10000.0                           0   \n",
       "16464      0  ...    1603.0    1903.0    2006.0                           0   \n",
       "22386      2  ...   13000.0    5500.0    1000.0                           1   \n",
       "\n",
       "         DIFF_1    DIFF_2    DIFF_3    DIFF_4    DIFF_5    DIFF_6  \n",
       "25665   27691.0   23391.0   13600.0  -22373.0   43344.0    8697.0  \n",
       "16464   72450.0   67967.0   51169.0   49272.0   48469.0   47464.0  \n",
       "22386  149110.0  152319.0  161487.0  144577.0  162594.0  169922.0  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import shap\n",
    "\n",
    "# log_explainer = shap.KernelExplainer(LogisticRegression(C=10, max_iter=500).fit(X_train, y_train).predict_proba, X_train)\n",
    "# shap_values = log_explainer.shap_values(X_test)\n",
    "# shap.force_plot(\n",
    "#     log_explainer.expected_value[0],\n",
    "#     shap_values[0][0, :],\n",
    "#     X_test.iloc[0, :],\n",
    "#     matplotlib=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 13. Summary of results <a name=\"13\"></a>\n",
    "<hr>\n",
    "rubric={points:12}\n",
    "\n",
    "Imagine that you want to present the summary of these results to your boss and co-workers. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Create a table summarizing important results. \n",
    "2. Write concluding remarks.\n",
    "3. Discuss other ideas that you did not try but could potentially improve the performance/interpretability . \n",
    "3. Report your final test score along with the metric you used at the top of this notebook in the [Submission instructions section](#si)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_13\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The model produced in this assignment didn't seem to work too well as all of the training, validation, and test scores were in the low 80's.  Improvements could have been made with feature engineering and transformations and how the model was produced.\n",
    "I could try scaling the features differently, extending the range of my hyperparameter searches, and choosing different types of transformations for the features.\n",
    "My final test score is 0.814."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## (Optional) 14. Your takeaway <a name=\"15\"></a>\n",
    "<hr>\n",
    "rubric={points:2}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "What is your biggest takeaway from the supervised machine learning material we have learned so far? Please write thoughtful answers.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_14\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to consider both the intuitive and practical implications of transformations, engineering, and selection of features to ensure that we produce a model that reflects the real world as accurately as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PLEASE READ BEFORE YOU SUBMIT:** \n",
    "\n",
    "When you are ready to submit your assignment do the following:\n",
    "\n",
    "1. Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`. \n",
    "2. Notebooks with cell execution numbers out of order or not starting from \"1\" will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
    "4. Upload the assignment using Gradescope's drag and drop tool. Check out this [Gradescope Student Guide](https://lthub.ubc.ca/guides/gradescope-student-guide/) if you need help with Gradescope submission. \n",
    "5. Make sure that the plots and output are rendered properly in your submitted file. If the .ipynb file is too big and doesn't render on Gradescope, also upload a pdf or html in addition to the .ipynb so that the TAs can view your submission on Gradescope. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a tricky one but you did it! Have a great weekend! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/eva-well-done.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-cpsc330]",
   "language": "python",
   "name": "conda-env-.conda-cpsc330-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
