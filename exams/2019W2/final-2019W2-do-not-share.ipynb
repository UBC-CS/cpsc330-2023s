{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPSC 330 final exam\n",
    "\n",
    "The University of British Columbia\n",
    "\n",
    "Instructor: Mike Gelbart\n",
    "\n",
    "April 24, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "#### What is / is not allowed.\n",
    "\n",
    "- This exam is open book. You are welcome to consult the course materials, online resources, etc.\n",
    "- You are allowed to copy/adapt/reuse code from the course materials (lectures, my homework solutions, your homework solutions) **with attribution**.\n",
    "  - For each of the coding questions, there is a section underneath that asks you to list the resources you borrowed code from. \n",
    "  - Using code from the course materials without attribution may be considered academic misconduct.\n",
    "- You are **not** allowed to copy/adapt/reuse code from anywhere other than course materials.\n",
    "  - Using code from anywhere other than the course materials will be considered academic misconduct.\n",
    "- You are **not** allowed to copy text, visualizations, or anything other than code from anywhere.\n",
    "- You are **not** allowed to communicate with **anyone else, in any way** during the exam. \n",
    "  - This includes talking in-person, phone, text, chat apps, screen sharing, email, sharing your notebook, or any form of communication. \n",
    "  - This restriction applies to any other person, regardless of whether or not they are enrolled in CPSC 330.\n",
    "\n",
    "#### Submission instructions.\n",
    "\n",
    "- You will receive and submit your exam notebook the same way you submit your homework, through github.students.cs.ubc.ca. \n",
    "- As with the homework assignments, **you must ensure that all your code outputs (scores, tables, figures, etc.) are displayed in the notebook**. For example, if you are required to calculate some value, it is not sufficient to just store the value to a variable, nor is it sufficient to have a `print(value)` in your code - the print code must actually be run and the notebook saved, so that the output is shown on the screen when the notebook is rendered. This allows us see your results without running your code. \n",
    "  - When you are done, take a look at your rendered notebook in a web browser at github.students.cs.ubc.ca, to make sure all the output is displayed properly.\n",
    "- **It is essential that you commit and push your work to GitHub frequently.** If you have a connection problem at the end of the exam and you miss the deadline, we will grade your latest work that was successfully pushed. Thus, if you only try to push once at the end and something goes wrong, you will not have a submission and will receive zero. You have been warned.\n",
    "- You will gain read and write access to your repository at 12:00pm. You will lose write access to your repository at 2:30pm.\n",
    "- Answer the questions directly in this notebook, in the same way that you would for an assignment.\n",
    "\n",
    "#### System requirements.\n",
    "\n",
    "- You will need a computer with Python 3, Jupyter, and the main Python packages we have used in the course, such as pandas, scikit-learn, matplotlib, etc. \n",
    "- You will not need any of the \"extra\" packages in the course, such as graphviz, pandas_profiling, tensorflow, gensim, xgboost, lightgbm, catboost, lifelines, shap, etc.\n",
    "- If you are using the same system as you used for the homework assignments, you should be fine.\n",
    "- If you are using a new or different system than the one you used during the course, please make sure you can run all the homework solutions before the exam starts. \n",
    "- I have tried to create the exam such that you don't need to do any heavy-duty computations. \n",
    "  - If something is running too slowly on your machine, try something else and just add a quick note explaining that the code was too slow.\n",
    "\n",
    "#### Questions and announcements.\n",
    "\n",
    "- If I need to make any announcements or clarifications during the exam, I will post them as followup discussions on [this Piazza thread](https://piazza.com/class/k1gx4b3djbv3ph?cid=388).\n",
    "- You are responsible for monitoring Piazza for any announcements or clarifications.\n",
    "- If you have questions during the exam, send me a **private** post on Piazza. \n",
    "  - I have enabled private posts.\n",
    "  - I will check Piazza regularly during the exam.\n",
    "  - I will respond through the same private message thread on Piazza.\n",
    "  - I will answer questions in the order they are received. \n",
    "  \n",
    "#### Contingency plans.\n",
    "\n",
    "- In the unlikely event that Piazza goes down during the exam, I will post announcements at the top of the course website README [here](https://github.students.cs.ubc.ca/cpsc330-2019w-t2/home). If you have a private question, email me at mgelbart@cs.ubc.ca.\n",
    "- In the unlikely event that github.students.cs.ubc.ca goes down during the start of the exam, I will distribute the exam by posting it on Piazza.\n",
    "- In the unlikely event that github.students.cs.ubc.ca goes down at the end of the exam, email your completed exam to mgelbart@cs.ubc.ca before the end time.\n",
    "  - **Please do not** email me the exam if github.students.cs.ubc.ca is working. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrity Pledge\n",
    "\n",
    "This is an online exam without invigilation. I, and your fellow classmates, are trusting you to approach this exam honourably and abide by the rules. The two main problems with cheating are (1) you might get caught and (2) you are permanently changing your path through your life in a way that you may later regret. \n",
    "\n",
    "IMHO it is easier to recover from a low grade than it is to recover from being a person who conducted themselves dishonestly. In case you disagree with me on that, hopefully problem (1) will deter you from cheating. \n",
    "\n",
    "We will be using the integrity pledge wording set out by the Faculty of Science:\n",
    "\n",
    "> I hereby pledge that I have read and will abide by the rules, regulations, and expectations set out in the Academic Calendar, with particular attention paid to:\n",
    "> 1. [The Student Declaration](http://www.calendar.ubc.ca/vancouver/index.cfm?tree=3,285,0,0)\n",
    "> 2. [The Academic Honesty and Standards](http://www.calendar.ubc.ca/vancouver/index.cfm?tree=3,286,0,0)\n",
    "> 3. [The Student Conduct During Examinations](http://www.calendar.ubc.ca/vancouver/index.cfm?tree=3,41,90,0)\n",
    "> 4. And any special rules for conduct as set out by the examiner.\n",
    "\n",
    "As far as \"special rules\" are concerned, please refer to the \"What is / is not allowed.\" section in the Instructions above. \n",
    "\n",
    "The following wording is also from the Faculty of Science:\n",
    "\n",
    "> I affirm that I will not give or receive any unauthorized help on this examination, that all work will be my own, and that I will abide by any special rules for conduct set out by the examiner.\n",
    "\n",
    "<font color='red'>**In the markdown cell below, you are required to re-type, or copy/paste, the sentence above, and then \"sign\" your name (i.e. type your full name underneath it).**</font> Please do it now so you don't forget."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_copy the sentence starting with \"I affirm\" here_\n",
    "\n",
    "_put your name here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- Q1 (5 points)\n",
    "- Q2 (5 points)\n",
    "- Q3 (15 points) \n",
    "- Q4 (20 points)\n",
    "- Q5 (10 points)\n",
    "- Q6 (20 points)\n",
    "- Q7 (25 points)\n",
    "\n",
    "Total: 100 points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Canadian Cheese Directory\n",
    "\n",
    "In this exam, we will be looking at the [Canadian Cheese Directory dataset](https://open.canada.ca/data/en/dataset/3c16cd48-3ac3-453f-8260-6f745181c83b) from Agriculture and Agri-Food Canada. Because this data is distributed under the [Canadian Open Government License](https://open.canada.ca/en/open-government-licence-canada), I was able to include the data in your final exam repositories, so you should not need to download the dataset. The following code should run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"canadianCheeseDirectory.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be predicting `FatContentPercent`, which is not available for all the cheeses, so I will first filter out those where this is not available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['FatContentPercent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CheeseNameEn', 'CheeseNameFr', 'ManufacturerNameEn',\n",
       "       'ManufacturerNameFr', 'ManufacturerProvCode', 'ManufacturingTypeEn',\n",
       "       'ManufacturingTypeFr', 'WebSiteEn', 'WebSiteFr', 'FatContentPercent',\n",
       "       'MoisturePercent', 'ParticularitiesEn', 'ParticularitiesFr',\n",
       "       'FlavourEn', 'FlavourFr', 'CharacteristicsEn', 'CharacteristicsFr',\n",
       "       'RipeningEn', 'RipeningFr', 'Organic', 'CategoryTypeEn',\n",
       "       'CategoryTypeFr', 'MilkTypeEn', 'MilkTypeFr', 'MilkTreatmentTypeEn',\n",
       "       'MilkTreatmentTypeFr', 'RindTypeEn', 'RindTypeFr', 'LastUpdateDate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns are duplicated in English and French (e.g. `MilkTypeEn` vs. `MilkTypeFr`). In most cases, this is just duplicated information and we can drop the French columns. However, in two cases we need to first merge the English and French columns because the information may be stored in either column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ManufacturerName\"] = df[\"ManufacturerNameEn\"].fillna(df[\"ManufacturerNameFr\"])\n",
    "df = df.drop(columns=[\"ManufacturerNameEn\", \"ManufacturerNameFr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"CheeseName\"] = df[\"CheeseNameEn\"].fillna(df[\"CheeseNameFr\"])\n",
    "df = df.drop(columns=[\"CheeseNameEn\", \"CheeseNameFr\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to drop all the French columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ManufacturerProvCode', 'ManufacturingTypeEn', 'WebSiteEn',\n",
       "       'FatContentPercent', 'MoisturePercent', 'ParticularitiesEn',\n",
       "       'FlavourEn', 'CharacteristicsEn', 'RipeningEn', 'Organic',\n",
       "       'CategoryTypeEn', 'MilkTypeEn', 'MilkTreatmentTypeEn', 'RindTypeEn',\n",
       "       'LastUpdateDate', 'ManufacturerName', 'CheeseName'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=[col for col in df.columns if col.endswith(\"Fr\")])\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll do the train/test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will start with a bit of exploration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ManufacturerProvCode</th>\n",
       "      <th>ManufacturingTypeEn</th>\n",
       "      <th>WebSiteEn</th>\n",
       "      <th>FatContentPercent</th>\n",
       "      <th>MoisturePercent</th>\n",
       "      <th>ParticularitiesEn</th>\n",
       "      <th>FlavourEn</th>\n",
       "      <th>CharacteristicsEn</th>\n",
       "      <th>RipeningEn</th>\n",
       "      <th>Organic</th>\n",
       "      <th>CategoryTypeEn</th>\n",
       "      <th>MilkTypeEn</th>\n",
       "      <th>MilkTreatmentTypeEn</th>\n",
       "      <th>RindTypeEn</th>\n",
       "      <th>LastUpdateDate</th>\n",
       "      <th>ManufacturerName</th>\n",
       "      <th>CheeseName</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CheeseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>QC</td>\n",
       "      <td>Industrial</td>\n",
       "      <td>http://www.damafro.ca/en/home.html</td>\n",
       "      <td>22.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>Organic</td>\n",
       "      <td>Mild and acidulous</td>\n",
       "      <td>Creamy cheese</td>\n",
       "      <td>Unripened</td>\n",
       "      <td>1</td>\n",
       "      <td>Fresh Cheese</td>\n",
       "      <td>Goat</td>\n",
       "      <td>Pasteurized</td>\n",
       "      <td>No Rind</td>\n",
       "      <td>2016-02-03</td>\n",
       "      <td>Damafro</td>\n",
       "      <td>Chèvre des Alpes BIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2281</th>\n",
       "      <td>QC</td>\n",
       "      <td>Artisan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Candied fruit flavor with hints of caramel.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6 months</td>\n",
       "      <td>1</td>\n",
       "      <td>Firm Cheese</td>\n",
       "      <td>Cow</td>\n",
       "      <td>Raw Milk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-02-03</td>\n",
       "      <td>Fromagerie Au Gré des Champs</td>\n",
       "      <td>Frère Chasseur (Le)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908</th>\n",
       "      <td>QC</td>\n",
       "      <td>Artisan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unripened</td>\n",
       "      <td>0</td>\n",
       "      <td>Fresh Cheese</td>\n",
       "      <td>Goat</td>\n",
       "      <td>Pasteurized</td>\n",
       "      <td>No Rind</td>\n",
       "      <td>2016-02-03</td>\n",
       "      <td>Fromagerie Couland</td>\n",
       "      <td>Mon précieux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>QC</td>\n",
       "      <td>Artisan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Firm Cheese</td>\n",
       "      <td>Ewe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Washed Rind</td>\n",
       "      <td>2016-02-03</td>\n",
       "      <td>Maison d'affinage Maurice Dufour (La)</td>\n",
       "      <td>Tomme de Brebis de Charlevoix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>QC</td>\n",
       "      <td>Farmstead</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hazelnut flavour</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Firm Cheese</td>\n",
       "      <td>Cow</td>\n",
       "      <td>Pasteurized</td>\n",
       "      <td>No Rind</td>\n",
       "      <td>2016-02-03</td>\n",
       "      <td>Fromagerie Ferme du littoral</td>\n",
       "      <td>Cheddar Littoral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ManufacturerProvCode ManufacturingTypeEn  \\\n",
       "CheeseId                                            \n",
       "1432                       QC          Industrial   \n",
       "2281                       QC             Artisan   \n",
       "1908                       QC             Artisan   \n",
       "2224                       QC             Artisan   \n",
       "2007                       QC           Farmstead   \n",
       "\n",
       "                                   WebSiteEn  FatContentPercent  \\\n",
       "CheeseId                                                          \n",
       "1432      http://www.damafro.ca/en/home.html               22.0   \n",
       "2281                                     NaN               35.0   \n",
       "1908                                     NaN               22.0   \n",
       "2224                                     NaN               33.0   \n",
       "2007                                     NaN               30.0   \n",
       "\n",
       "          MoisturePercent ParticularitiesEn  \\\n",
       "CheeseId                                      \n",
       "1432                 58.0           Organic   \n",
       "2281                 33.0               NaN   \n",
       "1908                 69.0               NaN   \n",
       "2224                 33.0               NaN   \n",
       "2007                 42.0               NaN   \n",
       "\n",
       "                                            FlavourEn CharacteristicsEn  \\\n",
       "CheeseId                                                                  \n",
       "1432                               Mild and acidulous     Creamy cheese   \n",
       "2281      Candied fruit flavor with hints of caramel.               NaN   \n",
       "1908                                              NaN               NaN   \n",
       "2224                                              NaN               NaN   \n",
       "2007                                 Hazelnut flavour               NaN   \n",
       "\n",
       "         RipeningEn  Organic CategoryTypeEn MilkTypeEn MilkTreatmentTypeEn  \\\n",
       "CheeseId                                                                     \n",
       "1432      Unripened        1   Fresh Cheese       Goat         Pasteurized   \n",
       "2281       6 months        1    Firm Cheese        Cow            Raw Milk   \n",
       "1908      Unripened        0   Fresh Cheese       Goat         Pasteurized   \n",
       "2224            NaN        0    Firm Cheese        Ewe                 NaN   \n",
       "2007            NaN        0    Firm Cheese        Cow         Pasteurized   \n",
       "\n",
       "           RindTypeEn LastUpdateDate                       ManufacturerName  \\\n",
       "CheeseId                                                                      \n",
       "1432          No Rind     2016-02-03                                Damafro   \n",
       "2281              NaN     2016-02-03           Fromagerie Au Gré des Champs   \n",
       "1908          No Rind     2016-02-03                     Fromagerie Couland   \n",
       "2224      Washed Rind     2016-02-03  Maison d'affinage Maurice Dufour (La)   \n",
       "2007          No Rind     2016-02-03           Fromagerie Ferme du littoral   \n",
       "\n",
       "                             CheeseName  \n",
       "CheeseId                                 \n",
       "1432               Chèvre des Alpes BIO  \n",
       "2281                Frère Chasseur (Le)  \n",
       "1908                       Mon précieux  \n",
       "2224      Tomme de Brebis de Charlevoix  \n",
       "2007                   Cheddar Littoral  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 781 entries, 1432 to 2391\n",
      "Data columns (total 17 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   ManufacturerProvCode  781 non-null    object \n",
      " 1   ManufacturingTypeEn   781 non-null    object \n",
      " 2   WebSiteEn             441 non-null    object \n",
      " 3   FatContentPercent     781 non-null    float64\n",
      " 4   MoisturePercent       770 non-null    float64\n",
      " 5   ParticularitiesEn     337 non-null    object \n",
      " 6   FlavourEn             599 non-null    object \n",
      " 7   CharacteristicsEn     491 non-null    object \n",
      " 8   RipeningEn            503 non-null    object \n",
      " 9   Organic               781 non-null    int64  \n",
      " 10  CategoryTypeEn        762 non-null    object \n",
      " 11  MilkTypeEn            780 non-null    object \n",
      " 12  MilkTreatmentTypeEn   732 non-null    object \n",
      " 13  RindTypeEn            543 non-null    object \n",
      " 14  LastUpdateDate        781 non-null    object \n",
      " 15  ManufacturerName      781 non-null    object \n",
      " 16  CheeseName            781 non-null    object \n",
      "dtypes: float64(2), int64(1), object(14)\n",
      "memory usage: 109.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I'll split up the features into the various types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['MoisturePercent']\n",
    "categorical_features = ['ManufacturerProvCode', 'ManufacturingTypeEn', 'Organic', 'CategoryTypeEn', 'MilkTypeEn', 'MilkTreatmentTypeEn', 'RindTypeEn']\n",
    "text_features = ['CheeseName', 'FlavourEn', 'CharacteristicsEn']\n",
    "drop_features = ['WebSiteEn', 'ParticularitiesEn', 'RipeningEn', 'LastUpdateDate', 'ManufacturerName']\n",
    "target_column = 'FatContentPercent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(numeric_features + categorical_features + text_features + drop_features + [target_column]) == set(df_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1: cheese ripening\n",
    "rubric={points:5}\n",
    "\n",
    "I decided to drop the feature `RipeningEn` because it was a hassle to deal with. Here are the unique values of this feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Unripened', '6 months', nan, '3 Months', 'Less than 1 Month',\n",
       "       '2 Months', '9 Months', '2 months', '4 Months',\n",
       "       'More than 5 Years', '2 to 5 year', '6 Months', '2 Years', 'None',\n",
       "       '10 day minimum', '10 days minimum', '1 Month', 'Minimum 10 days',\n",
       "       '4 Years', '3 months', '2 weeks', '30 days', '3 to 6 months',\n",
       "       '1 to 5 year', '1 Year', 'unripened', '18 Months', '6 or 7 weeks',\n",
       "       '90 days', '4 months', '5 Months', '15 Months', '10 days',\n",
       "       '3 Years', '3 years', '30 days in brine', '12 months', '2 days',\n",
       "       '1 month', '10 Months', 'Unriped', '5 days', '45 days', '3 weeks',\n",
       "       '3 to 5 months', '60 days', '5 Years', '1 year', '80 days',\n",
       "       '2-3 months', '5 months', '9 months', 'Not required to ripen.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['RipeningEn'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe how you would preprocess this feature into something useful. What type of feature (numeric, categorical, etc) would you end up with? Are there special cases you would need to handle? **Max 3 sentences**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "I would turn this into a numeric feature for number of days (or months) of ripening, with unripened set to 0. There would be some judgement calls involved, e.g. setting \"10 day minimum\" to \"10 days\", \"2-3 months\" to 2.5 months, \"More than 5 Years\" to 5 years, etc.\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2: target values\n",
    "rubric={points:5}\n",
    "\n",
    "Make an argument for or against log-transforming the target values in this problem. A good answer will reference this particular problem we're working on, rather than being generally applicable to any problem. **Max 3 sentences.**\n",
    "\n",
    "Note: regardless of your argument, please do **not** transform your targets in the code below, as this would make your exam harder to grade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're trying to predict the percent fat of the cheese. Here is a histogram of the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train[target_column].plot.hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't have any particularly extreme values here; indeed, that would not be possible since they are percentages and must be between 0 and 100. It seems reasonable to minimize mean squared error and stick to the original units. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll preprocess the features. This should look fairly familiar to you, except for the preprocessing of text features. In [hw5](https://github.students.cs.ubc.ca/cpsc330-2019w-t2/home/blob/master/hw-solutions/hw5/hw5.ipynb) we also mixed text features with other features, but in that case we did not actually put the `CountVectorizer` directly into the `ColumnTransformer`, which I am doing here. Furthermore, there are 3 text columns and I am creating a separate `CountVectorizer` for each one. You do not need to understand every detail, but just understand generally what it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train[target_column]\n",
    "y_test = df_test[target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant')),\n",
    "    ('onehot', OneHotEncoder(sparse=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Fit a separate CountVectorizer for each of the text columns.\n",
    "# Need to convert the resulting sparse matrices to dense separately.\n",
    "text_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='')),\n",
    "    ('tolist', FunctionTransformer(lambda x: x.ravel(), validate=False)),\n",
    "    ('countvec', CountVectorizer(max_features=10, stop_words='english')),\n",
    "    ('todense', FunctionTransformer(lambda x: x.toarray(), validate=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('numeric', numeric_transformer, numeric_features),\n",
    "    ('categorical', categorical_transformer, categorical_features)\n",
    "] + [(f, text_transformer, [f]) for f in text_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor.fit(df_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_names(preprocessor):\n",
    "    \"\"\"\n",
    "    Gets the feature names from a preprocessor.\n",
    "    This entails looking at the OHE feature names and also\n",
    "    the words used by the CountVectorizers.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    preprocessor: ColumnTransformer\n",
    "        A fit preprocessor following the specific format above.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        A list of column names.\n",
    "    \"\"\"\n",
    "    ohe_feature_names = list(preprocessor.named_transformers_['categorical'].named_steps['onehot'].get_feature_names(categorical_features))\n",
    "    text_feature_names = [f + \"_\" + word for f in text_features for word in preprocessor.named_transformers_[f].named_steps['countvec'].get_feature_names()]\n",
    "    return numeric_features + ohe_feature_names + text_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MoisturePercent</th>\n",
       "      <th>ManufacturerProvCode_AB</th>\n",
       "      <th>ManufacturerProvCode_BC</th>\n",
       "      <th>ManufacturerProvCode_MB</th>\n",
       "      <th>ManufacturerProvCode_NB</th>\n",
       "      <th>ManufacturerProvCode_NL</th>\n",
       "      <th>ManufacturerProvCode_NS</th>\n",
       "      <th>ManufacturerProvCode_ON</th>\n",
       "      <th>ManufacturerProvCode_PE</th>\n",
       "      <th>ManufacturerProvCode_QC</th>\n",
       "      <th>...</th>\n",
       "      <th>CharacteristicsEn_cheese</th>\n",
       "      <th>CharacteristicsEn_colored</th>\n",
       "      <th>CharacteristicsEn_creamy</th>\n",
       "      <th>CharacteristicsEn_interior</th>\n",
       "      <th>CharacteristicsEn_pressed</th>\n",
       "      <th>CharacteristicsEn_rind</th>\n",
       "      <th>CharacteristicsEn_ripened</th>\n",
       "      <th>CharacteristicsEn_smooth</th>\n",
       "      <th>CharacteristicsEn_texture</th>\n",
       "      <th>CharacteristicsEn_white</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CheeseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>1.127656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2281</th>\n",
       "      <td>-1.459684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908</th>\n",
       "      <td>2.266086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>-1.459684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>-0.528242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          MoisturePercent  ManufacturerProvCode_AB  ManufacturerProvCode_BC  \\\n",
       "CheeseId                                                                      \n",
       "1432             1.127656                      0.0                      0.0   \n",
       "2281            -1.459684                      0.0                      0.0   \n",
       "1908             2.266086                      0.0                      0.0   \n",
       "2224            -1.459684                      0.0                      0.0   \n",
       "2007            -0.528242                      0.0                      0.0   \n",
       "\n",
       "          ManufacturerProvCode_MB  ManufacturerProvCode_NB  \\\n",
       "CheeseId                                                     \n",
       "1432                          0.0                      0.0   \n",
       "2281                          0.0                      0.0   \n",
       "1908                          0.0                      0.0   \n",
       "2224                          0.0                      0.0   \n",
       "2007                          0.0                      0.0   \n",
       "\n",
       "          ManufacturerProvCode_NL  ManufacturerProvCode_NS  \\\n",
       "CheeseId                                                     \n",
       "1432                          0.0                      0.0   \n",
       "2281                          0.0                      0.0   \n",
       "1908                          0.0                      0.0   \n",
       "2224                          0.0                      0.0   \n",
       "2007                          0.0                      0.0   \n",
       "\n",
       "          ManufacturerProvCode_ON  ManufacturerProvCode_PE  \\\n",
       "CheeseId                                                     \n",
       "1432                          0.0                      0.0   \n",
       "2281                          0.0                      0.0   \n",
       "1908                          0.0                      0.0   \n",
       "2224                          0.0                      0.0   \n",
       "2007                          0.0                      0.0   \n",
       "\n",
       "          ManufacturerProvCode_QC  ...  CharacteristicsEn_cheese  \\\n",
       "CheeseId                           ...                             \n",
       "1432                          1.0  ...                       1.0   \n",
       "2281                          1.0  ...                       0.0   \n",
       "1908                          1.0  ...                       0.0   \n",
       "2224                          1.0  ...                       0.0   \n",
       "2007                          1.0  ...                       0.0   \n",
       "\n",
       "          CharacteristicsEn_colored  CharacteristicsEn_creamy  \\\n",
       "CheeseId                                                        \n",
       "1432                            0.0                       1.0   \n",
       "2281                            0.0                       0.0   \n",
       "1908                            0.0                       0.0   \n",
       "2224                            0.0                       0.0   \n",
       "2007                            0.0                       0.0   \n",
       "\n",
       "          CharacteristicsEn_interior  CharacteristicsEn_pressed  \\\n",
       "CheeseId                                                          \n",
       "1432                             0.0                        0.0   \n",
       "2281                             0.0                        0.0   \n",
       "1908                             0.0                        0.0   \n",
       "2224                             0.0                        0.0   \n",
       "2007                             0.0                        0.0   \n",
       "\n",
       "          CharacteristicsEn_rind  CharacteristicsEn_ripened  \\\n",
       "CheeseId                                                      \n",
       "1432                         0.0                        0.0   \n",
       "2281                         0.0                        0.0   \n",
       "1908                         0.0                        0.0   \n",
       "2224                         0.0                        0.0   \n",
       "2007                         0.0                        0.0   \n",
       "\n",
       "          CharacteristicsEn_smooth  CharacteristicsEn_texture  \\\n",
       "CheeseId                                                        \n",
       "1432                           0.0                        0.0   \n",
       "2281                           0.0                        0.0   \n",
       "1908                           0.0                        0.0   \n",
       "2224                           0.0                        0.0   \n",
       "2007                           0.0                        0.0   \n",
       "\n",
       "          CharacteristicsEn_white  \n",
       "CheeseId                           \n",
       "1432                          0.0  \n",
       "2281                          0.0  \n",
       "1908                          0.0  \n",
       "2224                          0.0  \n",
       "2007                          0.0  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_columns = get_column_names(preprocessor)\n",
    "    \n",
    "df_train_enc = pd.DataFrame(preprocessor.transform(df_train), index=df_train.index, columns=new_columns)\n",
    "df_train_enc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3: initial models\n",
    "rubric={points:15}\n",
    "\n",
    "Let's compare three approaches:\n",
    "\n",
    "1. A baseline model: choose either `DummyClassifier` or `DummyRegressor`, whichever is appropriate for this problem. \n",
    "2. A linear model: choose either `Ridge` or `LogisticRegression`, whichever is appropriate for this problem.\n",
    "3. A random forest model: choose either `RandomForestClassifier` or `RandomForestRegressor`, whichever is appropriate for this problem.\n",
    "\n",
    "For now, just use default hyperparameters.\n",
    "\n",
    "Report the train and cross-validation score in each case. Which model performs best with default hyperparameters?\n",
    "\n",
    "Don't violate the Golden Rule!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first point is to realize this is a regression problem because the target variable is continuous, so we want `DummyRegressor`, `Ridge`, and `RandomForestRegressor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_score    0.000000\n",
       "test_score    -0.021801\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_dummy = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', DummyRegressor())])\n",
    "\n",
    "scores_dummy = cross_validate(pipeline_dummy, df_train, y_train, cv=5, return_train_score=True)\n",
    "pd.DataFrame(scores_dummy)[[\"train_score\", \"test_score\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_score    0.561048\n",
       "test_score     0.458602\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_linear = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', Ridge())])\n",
    "\n",
    "scores_linear = cross_validate(pipeline_linear, df_train, y_train, cv=5, return_train_score=True)\n",
    "pd.DataFrame(scores_linear)[[\"train_score\", \"test_score\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_score    0.880548\n",
       "test_score     0.534209\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_rf = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestRegressor())])\n",
    "\n",
    "scores_rf = cross_validate(pipeline_rf, df_train, y_train, cv=5, return_train_score=True)\n",
    "pd.DataFrame(scores_rf)[[\"train_score\", \"test_score\"]].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, in nicer code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dummy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.021801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear</th>\n",
       "      <td>0.561048</td>\n",
       "      <td>0.458602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>0.878551</td>\n",
       "      <td>0.538744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               train_score  test_score\n",
       "dummy             0.000000   -0.021801\n",
       "linear            0.561048    0.458602\n",
       "random forest     0.878551    0.538744"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {'dummy' : DummyRegressor(),\n",
    "          'linear' : Ridge(),\n",
    "          'random forest' : RandomForestRegressor()\n",
    "         }\n",
    "\n",
    "avg_scores = dict()\n",
    "for model_name, model in models.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)])\n",
    "    scores = cross_validate(pipeline, df_train, y_train, cv=5, return_train_score=True)\n",
    "    avg_scores[model_name] = pd.DataFrame(scores)[[\"train_score\", \"test_score\"]].mean()\n",
    "avg_scores_df = pd.DataFrame(avg_scores).T\n",
    "avg_scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the random forest performs best so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you used code from the course materials (lecture, homework) in the above question, please list what resources you used (e.g. \"Lecture 5\", \"hw5\"). You do not need to specify exactly which lines of code you used, just the resources you took code from.\n",
    "\n",
    "- Resource 1\n",
    "- Resource 2\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4: hyperparameter tuning\n",
    "rubric={points:20}\n",
    "\n",
    "- Using an automated hyperparameter tuning method of your choice, make a reasonable attempt at tuning the hyperperameters for your linear model and random forest model. An excellent solution will also involve tuning the hyperparameters of the preprocessing steps. \n",
    "- Briefly justify your choices of which hyperparameters your tuned and what sorts of values you tried. **Max 3 sentences.**\n",
    "- Briefly discuss your scores after tuning. **Max 3 sentences.**\n",
    "\n",
    "Note: your time is limited, so there is no need to perform large searches that take a long time to run. My code for this question takes about 1.5 minutes to run on my laptop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll start with the linear regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_linear = {\n",
    "    'model__alpha': [1.0, 10, 100]\n",
    "}\n",
    "for text_feature in text_features:\n",
    "    param_grid_linear['preprocessor__' + text_feature + '__countvec__max_features'] = [10, 30, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will tune the main model parameter, `alpha`, and the number of features from each of the 3 `CountVectorizer` transformers. These seems more important to me than, say, the strategy of the imputer or the stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 405 out of 405 | elapsed:   31.8s finished\n"
     ]
    }
   ],
   "source": [
    "grid_search_linear = GridSearchCV(pipeline_linear, param_grid_linear, cv=5, verbose=1)\n",
    "grid_search_linear.fit(df_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_model__alpha</th>\n",
       "      <th>param_preprocessor__CharacteristicsEn__countvec__max_features</th>\n",
       "      <th>param_preprocessor__CheeseName__countvec__max_features</th>\n",
       "      <th>param_preprocessor__FlavourEn__countvec__max_features</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.047188</td>\n",
       "      <td>0.002855</td>\n",
       "      <td>0.016753</td>\n",
       "      <td>0.001124</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>{'model__alpha': 10, 'preprocessor__Characteri...</td>\n",
       "      <td>0.710477</td>\n",
       "      <td>0.407516</td>\n",
       "      <td>0.446779</td>\n",
       "      <td>0.643733</td>\n",
       "      <td>0.479246</td>\n",
       "      <td>0.537550</td>\n",
       "      <td>0.118090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.047745</td>\n",
       "      <td>0.002935</td>\n",
       "      <td>0.018632</td>\n",
       "      <td>0.003012</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>{'model__alpha': 10, 'preprocessor__Characteri...</td>\n",
       "      <td>0.700513</td>\n",
       "      <td>0.404888</td>\n",
       "      <td>0.449300</td>\n",
       "      <td>0.641099</td>\n",
       "      <td>0.487780</td>\n",
       "      <td>0.536716</td>\n",
       "      <td>0.114140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.048107</td>\n",
       "      <td>0.004229</td>\n",
       "      <td>0.016975</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>{'model__alpha': 10, 'preprocessor__Characteri...</td>\n",
       "      <td>0.701668</td>\n",
       "      <td>0.400151</td>\n",
       "      <td>0.448228</td>\n",
       "      <td>0.639014</td>\n",
       "      <td>0.479699</td>\n",
       "      <td>0.533752</td>\n",
       "      <td>0.116070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.048509</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>0.017119</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>{'model__alpha': 10, 'preprocessor__Characteri...</td>\n",
       "      <td>0.691675</td>\n",
       "      <td>0.397827</td>\n",
       "      <td>0.451502</td>\n",
       "      <td>0.637933</td>\n",
       "      <td>0.489030</td>\n",
       "      <td>0.533593</td>\n",
       "      <td>0.112280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.047365</td>\n",
       "      <td>0.003724</td>\n",
       "      <td>0.016173</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>{'model__alpha': 10, 'preprocessor__Characteri...</td>\n",
       "      <td>0.690345</td>\n",
       "      <td>0.407617</td>\n",
       "      <td>0.435410</td>\n",
       "      <td>0.635231</td>\n",
       "      <td>0.496563</td>\n",
       "      <td>0.533033</td>\n",
       "      <td>0.111158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "rank_test_score                                                                 \n",
       "1                     0.047188      0.002855         0.016753        0.001124   \n",
       "2                     0.047745      0.002935         0.018632        0.003012   \n",
       "3                     0.048107      0.004229         0.016975        0.001467   \n",
       "4                     0.048509      0.001438         0.017119        0.002003   \n",
       "5                     0.047365      0.003724         0.016173        0.000450   \n",
       "\n",
       "                param_model__alpha  \\\n",
       "rank_test_score                      \n",
       "1                               10   \n",
       "2                               10   \n",
       "3                               10   \n",
       "4                               10   \n",
       "5                               10   \n",
       "\n",
       "                param_preprocessor__CharacteristicsEn__countvec__max_features  \\\n",
       "rank_test_score                                                                 \n",
       "1                                                              100              \n",
       "2                                                              100              \n",
       "3                                                              100              \n",
       "4                                                              100              \n",
       "5                                                               10              \n",
       "\n",
       "                param_preprocessor__CheeseName__countvec__max_features  \\\n",
       "rank_test_score                                                          \n",
       "1                                                               30       \n",
       "2                                                              100       \n",
       "3                                                               30       \n",
       "4                                                              100       \n",
       "5                                                              100       \n",
       "\n",
       "                param_preprocessor__FlavourEn__countvec__max_features  \\\n",
       "rank_test_score                                                         \n",
       "1                                                               10      \n",
       "2                                                               10      \n",
       "3                                                               30      \n",
       "4                                                               30      \n",
       "5                                                               10      \n",
       "\n",
       "                                                            params  \\\n",
       "rank_test_score                                                      \n",
       "1                {'model__alpha': 10, 'preprocessor__Characteri...   \n",
       "2                {'model__alpha': 10, 'preprocessor__Characteri...   \n",
       "3                {'model__alpha': 10, 'preprocessor__Characteri...   \n",
       "4                {'model__alpha': 10, 'preprocessor__Characteri...   \n",
       "5                {'model__alpha': 10, 'preprocessor__Characteri...   \n",
       "\n",
       "                 split0_test_score  split1_test_score  split2_test_score  \\\n",
       "rank_test_score                                                            \n",
       "1                         0.710477           0.407516           0.446779   \n",
       "2                         0.700513           0.404888           0.449300   \n",
       "3                         0.701668           0.400151           0.448228   \n",
       "4                         0.691675           0.397827           0.451502   \n",
       "5                         0.690345           0.407617           0.435410   \n",
       "\n",
       "                 split3_test_score  split4_test_score  mean_test_score  \\\n",
       "rank_test_score                                                          \n",
       "1                         0.643733           0.479246         0.537550   \n",
       "2                         0.641099           0.487780         0.536716   \n",
       "3                         0.639014           0.479699         0.533752   \n",
       "4                         0.637933           0.489030         0.533593   \n",
       "5                         0.635231           0.496563         0.533033   \n",
       "\n",
       "                 std_test_score  \n",
       "rank_test_score                  \n",
       "1                      0.118090  \n",
       "2                      0.114140  \n",
       "3                      0.116070  \n",
       "4                      0.112280  \n",
       "5                      0.111158  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_linear_results = pd.DataFrame(grid_search_linear.cv_results_).set_index(\"rank_test_score\").sort_index()\n",
    "grid_search_linear_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I'll do the random forest. I'll use the same approach as for linear regression. However, the random forests are slower to train and I don't want the code to take too long, so I'll reduce the number of search cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_rf = {\n",
    "    \"model__n_estimators\" : [10, 30, 100]\n",
    "}\n",
    "\n",
    "for text_feature in text_features:\n",
    "    param_grid_rf['preprocessor__' + text_feature + '__countvec__max_features'] = [10, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   59.7s finished\n"
     ]
    }
   ],
   "source": [
    "grid_search_rf = GridSearchCV(pipeline_rf, param_grid_rf, cv=5, verbose=1)\n",
    "grid_search_rf.fit(df_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_model__n_estimators</th>\n",
       "      <th>param_preprocessor__CharacteristicsEn__countvec__max_features</th>\n",
       "      <th>param_preprocessor__CheeseName__countvec__max_features</th>\n",
       "      <th>param_preprocessor__FlavourEn__countvec__max_features</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.003539</td>\n",
       "      <td>0.031796</td>\n",
       "      <td>0.029907</td>\n",
       "      <td>0.004069</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>{'model__n_estimators': 100, 'preprocessor__Ch...</td>\n",
       "      <td>0.723395</td>\n",
       "      <td>0.500998</td>\n",
       "      <td>0.492636</td>\n",
       "      <td>0.649949</td>\n",
       "      <td>0.531946</td>\n",
       "      <td>0.579785</td>\n",
       "      <td>0.091256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.338877</td>\n",
       "      <td>0.076499</td>\n",
       "      <td>0.028075</td>\n",
       "      <td>0.001612</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>{'model__n_estimators': 100, 'preprocessor__Ch...</td>\n",
       "      <td>0.731965</td>\n",
       "      <td>0.485817</td>\n",
       "      <td>0.474682</td>\n",
       "      <td>0.663595</td>\n",
       "      <td>0.528949</td>\n",
       "      <td>0.577001</td>\n",
       "      <td>0.102572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.730354</td>\n",
       "      <td>0.060206</td>\n",
       "      <td>0.025934</td>\n",
       "      <td>0.001607</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>{'model__n_estimators': 100, 'preprocessor__Ch...</td>\n",
       "      <td>0.701379</td>\n",
       "      <td>0.468914</td>\n",
       "      <td>0.504461</td>\n",
       "      <td>0.674500</td>\n",
       "      <td>0.523763</td>\n",
       "      <td>0.574604</td>\n",
       "      <td>0.094580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.366965</td>\n",
       "      <td>0.029828</td>\n",
       "      <td>0.033163</td>\n",
       "      <td>0.019174</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>{'model__n_estimators': 30, 'preprocessor__Cha...</td>\n",
       "      <td>0.706771</td>\n",
       "      <td>0.512179</td>\n",
       "      <td>0.476759</td>\n",
       "      <td>0.646263</td>\n",
       "      <td>0.519950</td>\n",
       "      <td>0.572385</td>\n",
       "      <td>0.088358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.055906</td>\n",
       "      <td>0.062091</td>\n",
       "      <td>0.028733</td>\n",
       "      <td>0.003275</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>{'model__n_estimators': 100, 'preprocessor__Ch...</td>\n",
       "      <td>0.717728</td>\n",
       "      <td>0.504915</td>\n",
       "      <td>0.490050</td>\n",
       "      <td>0.637335</td>\n",
       "      <td>0.510553</td>\n",
       "      <td>0.572116</td>\n",
       "      <td>0.089997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "rank_test_score                                                                 \n",
       "1                     1.003539      0.031796         0.029907        0.004069   \n",
       "2                     1.338877      0.076499         0.028075        0.001612   \n",
       "3                     0.730354      0.060206         0.025934        0.001607   \n",
       "4                     0.366965      0.029828         0.033163        0.019174   \n",
       "5                     1.055906      0.062091         0.028733        0.003275   \n",
       "\n",
       "                param_model__n_estimators  \\\n",
       "rank_test_score                             \n",
       "1                                     100   \n",
       "2                                     100   \n",
       "3                                     100   \n",
       "4                                      30   \n",
       "5                                     100   \n",
       "\n",
       "                param_preprocessor__CharacteristicsEn__countvec__max_features  \\\n",
       "rank_test_score                                                                 \n",
       "1                                                               10              \n",
       "2                                                              100              \n",
       "3                                                               10              \n",
       "4                                                              100              \n",
       "5                                                              100              \n",
       "\n",
       "                param_preprocessor__CheeseName__countvec__max_features  \\\n",
       "rank_test_score                                                          \n",
       "1                                                              100       \n",
       "2                                                              100       \n",
       "3                                                              100       \n",
       "4                                                              100       \n",
       "5                                                              100       \n",
       "\n",
       "                param_preprocessor__FlavourEn__countvec__max_features  \\\n",
       "rank_test_score                                                         \n",
       "1                                                              100      \n",
       "2                                                              100      \n",
       "3                                                               10      \n",
       "4                                                               10      \n",
       "5                                                               10      \n",
       "\n",
       "                                                            params  \\\n",
       "rank_test_score                                                      \n",
       "1                {'model__n_estimators': 100, 'preprocessor__Ch...   \n",
       "2                {'model__n_estimators': 100, 'preprocessor__Ch...   \n",
       "3                {'model__n_estimators': 100, 'preprocessor__Ch...   \n",
       "4                {'model__n_estimators': 30, 'preprocessor__Cha...   \n",
       "5                {'model__n_estimators': 100, 'preprocessor__Ch...   \n",
       "\n",
       "                 split0_test_score  split1_test_score  split2_test_score  \\\n",
       "rank_test_score                                                            \n",
       "1                         0.723395           0.500998           0.492636   \n",
       "2                         0.731965           0.485817           0.474682   \n",
       "3                         0.701379           0.468914           0.504461   \n",
       "4                         0.706771           0.512179           0.476759   \n",
       "5                         0.717728           0.504915           0.490050   \n",
       "\n",
       "                 split3_test_score  split4_test_score  mean_test_score  \\\n",
       "rank_test_score                                                          \n",
       "1                         0.649949           0.531946         0.579785   \n",
       "2                         0.663595           0.528949         0.577001   \n",
       "3                         0.674500           0.523763         0.574604   \n",
       "4                         0.646263           0.519950         0.572385   \n",
       "5                         0.637335           0.510553         0.572116   \n",
       "\n",
       "                 std_test_score  \n",
       "rank_test_score                  \n",
       "1                      0.091256  \n",
       "2                      0.102572  \n",
       "3                      0.094580  \n",
       "4                      0.088358  \n",
       "5                      0.089997  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_rf_results = pd.DataFrame(grid_search_rf.cv_results_).set_index(\"rank_test_score\").sort_index()\n",
    "grid_search_rf_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameter tuning improved the linear regression score from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4586020565903324"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_scores_df.loc[\"linear\", \"test_score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5375502750606297"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_linear_results.loc[1, \"mean_test_score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the random forest score from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5387439761122478"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_scores_df.loc[\"random forest\", \"test_score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5797846657332967"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_rf_results.loc[1, \"mean_test_score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the random forest looks to be the best. The chosen hyerparameters are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__n_estimators': 100,\n",
       " 'preprocessor__CharacteristicsEn__countvec__max_features': 10,\n",
       " 'preprocessor__CheeseName__countvec__max_features': 100,\n",
       " 'preprocessor__FlavourEn__countvec__max_features': 100}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_rf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you used code from the course materials (lecture, homework) in the above question, please list what resources you used (e.g. \"Lecture 5\", \"hw5\"). You do not need to specify exactly which lines of code you used, just the resources you took code from.\n",
    "\n",
    "- Resource 1\n",
    "- Resource 2\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5: confidence and test set\n",
    "rubric={points:10}\n",
    "\n",
    "- For your best model from Q4, how confident are you in the score you reported? Base your answer on the sub-scores from the different folds of cross-validation. **Max 3 sentences.**\n",
    "- When you are done, compute your score on the test set. Is it what you expected? Briefly discuss. **Max 3 sentences.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could do a separate `cross_val_score` here, but for simplicitly I'll just look at the output of `GridSearchCV` for the 1st ranked model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split0_test_score    0.723395\n",
       "split1_test_score    0.500998\n",
       "split2_test_score    0.492636\n",
       "split3_test_score    0.649949\n",
       "split4_test_score    0.531946\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_rf_results.loc[1,grid_search_rf_results.columns[grid_search_rf_results.columns.str.startswith(\"split\")]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These scores vary a lot! So I would say, we are actually not very confident about our scores, or about this being the best model. This is likely due to the small number of examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's try our model on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5255701820892051"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_rf.score(df_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although this is not super close to our overall cross-validation score of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5797846657332967"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_rf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it is well within the range of values we saw from the cross-validation folds, so the result seems reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you used code from the course materials (lecture, homework) in the above question, please list what resources you used (e.g. \"Lecture 5\", \"hw5\"). You do not need to specify exactly which lines of code you used, just the resources you took code from.\n",
    "\n",
    "- Resource 1\n",
    "- Resource 2\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6: feature importances\n",
    "rubric={points:20}\n",
    "\n",
    "- What are your 5 most important features according to your tuned linear model?\n",
    "- What are your 5 most important features according to your tuned random forest model? \n",
    "- Do they agree with each other? Briefly discuss. **Max 3 sentences.**\n",
    "- Also, briefly discuss one other aspect of the feature importances that you find interesting. **Max 3 sentences.**\n",
    "\n",
    "Note: for the 5 most important features, it is sufficient to display these as code output rather than typing them as text, so long as they are displayed very clearly (i.e. only display those 5, don't leave them as part of a big list). \n",
    "\n",
    "Hint: assuming you've tuned your preprocessor, you'll want to use the `get_columns_names` function provided above because the column names may have changed during hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns_linear = get_column_names(grid_search_linear.best_estimator_.named_steps['preprocessor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_lr_coefs = grid_search_linear.best_estimator_.named_steps['model'].coef_\n",
    "lr_coefs = pd.DataFrame(data=tuned_lr_coefs, index=new_columns_linear, columns=[\"Coefficient\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 5 most important linear regression features, by absolute value of the coefficients, are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CheeseName_léger</th>\n",
       "      <td>-5.373263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MoisturePercent</th>\n",
       "      <td>-5.218202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CheeseName_damafro</th>\n",
       "      <td>4.770958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CheeseName_crème</th>\n",
       "      <td>3.965532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CheeseName_brie</th>\n",
       "      <td>2.574028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Coefficient\n",
       "CheeseName_léger      -5.373263\n",
       "MoisturePercent       -5.218202\n",
       "CheeseName_damafro     4.770958\n",
       "CheeseName_crème       3.965532\n",
       "CheeseName_brie        2.574028"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_coefs.loc[lr_coefs.abs().sort_values(by=\"Coefficient\", ascending=False)[:5].index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 5 most important random forest features are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns_rf = get_column_names(grid_search_rf.best_estimator_.named_steps['preprocessor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MoisturePercent</th>\n",
       "      <td>0.523820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CheeseName_damafro</th>\n",
       "      <td>0.040227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CheeseName_léger</th>\n",
       "      <td>0.032440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CategoryTypeEn_Firm Cheese</th>\n",
       "      <td>0.023843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CategoryTypeEn_Soft Cheese</th>\n",
       "      <td>0.017967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Importance\n",
       "MoisturePercent               0.523820\n",
       "CheeseName_damafro            0.040227\n",
       "CheeseName_léger              0.032440\n",
       "CategoryTypeEn_Firm Cheese    0.023843\n",
       "CategoryTypeEn_Soft Cheese    0.017967"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_rf_imps = grid_search_rf.best_estimator_.named_steps['model'].feature_importances_\n",
    "rf_imps = pd.DataFrame(data=tuned_rf_imps, index=new_columns_rf, columns=[\"Importance\"])\n",
    "rf_imps.sort_values(by=\"Importance\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both models have `MoisturePercent`, `CheeseName_léger` and `CheeseName_damafro` as a very important features. It seems that cheese with more moisture have less fat (I guess that makes sense) and cheeses with \"léger\" (meaning \"light\" in French) in the name also have less fat (makes sense!). I am not sure what \"damafro\" is but it seems to incidate more fat. For spots 4 and 5, the two models do not find the same important features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For something interesting, we can look at more of the linear regression coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CheeseName_damafro</th>\n",
       "      <td>4.770958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CheeseName_crème</th>\n",
       "      <td>3.965532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CheeseName_brie</th>\n",
       "      <td>2.574028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ManufacturerProvCode_SK</th>\n",
       "      <td>1.929272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CheeseName_feta</th>\n",
       "      <td>1.835116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CheeseName_mozzarella</th>\n",
       "      <td>-1.900473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CategoryTypeEn_Hard Cheese</th>\n",
       "      <td>-2.021599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CharacteristicsEn_fat</th>\n",
       "      <td>-2.477817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MoisturePercent</th>\n",
       "      <td>-5.218202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CheeseName_léger</th>\n",
       "      <td>-5.373263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Coefficient\n",
       "CheeseName_damafro             4.770958\n",
       "CheeseName_crème               3.965532\n",
       "CheeseName_brie                2.574028\n",
       "ManufacturerProvCode_SK        1.929272\n",
       "CheeseName_feta                1.835116\n",
       "...                                 ...\n",
       "CheeseName_mozzarella         -1.900473\n",
       "CategoryTypeEn_Hard Cheese    -2.021599\n",
       "CharacteristicsEn_fat         -2.477817\n",
       "MoisturePercent               -5.218202\n",
       "CheeseName_léger              -5.373263\n",
       "\n",
       "[181 rows x 1 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_coefs.sort_values(by=\"Coefficient\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the linear model picks out `CharacteristicsEn_fat` with a _negative_ coefficient - that is surprising! Let's investigate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Popular 6% cheese called that because of its low fat content. Made from pasteurized partially skimmed milk. Smooth cheese with a few holes',\n",
       "       'Available in Mozzarella - 20% milk fat, 25% milk fat, 16% milk fat, sliced',\n",
       "       'Low in fat'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"CharacteristicsEn\"][df_train[\"CharacteristicsEn\"].str.contains(\"fat\").fillna(False)].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah, it's because they talk about it being low fat!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you used code from the course materials (lecture, homework) in the above question, please list what resources you used (e.g. \"Lecture 5\", \"hw5\"). You do not need to specify exactly which lines of code you used, just the resources you took code from.\n",
    "\n",
    "- Resource 1\n",
    "- Resource 2\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7: short answer questions\n",
    "rubric={points:25}\n",
    "\n",
    "The following questions are worth 5 points each. These questions refer to specific lectures or homework assignments from the second half of the course. **Max 3 sentences each.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7(a): [**Lecture 15**](https://github.students.cs.ubc.ca/cpsc330-2019w-t2/home/blob/master/lectures/15_nearest-neighbours.ipynb)\n",
    "\n",
    "Instead of trying to predict the fat content of a cheese, let's say you wanted to solve a different problem: given a query cheese, find similar cheeses in the dataset. How would you approach this problem? Would any of the code above (in this notebook) be useful for this task?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "I would first encode the features and then use nearest neighbours like we did in hw6. Thus, the feature encoding/preprocesing code above would be useful. The rest of the code, perhaps not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7(b): [**Lecture 16**](https://github.students.cs.ubc.ca/cpsc330-2019w-t2/home/blob/master/lectures/16_time-series-data.ipynb)\n",
    "\n",
    "In [hw7](https://github.students.cs.ubc.ca/cpsc330-2019w-t2/home/blob/master/hw-solutions/hw7/hw7.ipynb) question 1(e) we used the current week's average avocado price as a baseline prediction for next week's avocado price. Under what circumstances would this approach yield particularly good or bad predictions of next week's avocado price?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "If the average avocado prices changes very slowly then using last week's price would give decent predictions. If it fluctuates rapidly then you would get bad predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7(c): [**Lecture 17**](https://github.students.cs.ubc.ca/cpsc330-2019w-t2/home/blob/master/lectures/17_survival-analysis.ipynb)\n",
    "\n",
    "In Lecture 17 we looked at a customer churn dataset with a binary target column (yes/no) for whether a customer churned, and a `tenure` column for the length of time. In Lecture 16 we looked at the rain in Australia dataset which has a binary target column (yes/no) for whether it would rain tomorrow and a `Date` column for the time stamp. Both of these are binary classification problems, and both involve changes over time. Why did we have to worry about censoring for the churn dataset but not the rain dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "For the churn dataset we have an event (churn) that eventually happens but we don't know when. Thus, at the time of our measurements, we see some un-churned customers and we don't know when they will eventually churn (censorship). In the rain dataset we simply have a sequence of days and there is no notion of waiting for something to eventually happen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7(d): [**Lecture 19**](https://github.students.cs.ubc.ca/cpsc330-2019w-t2/home/blob/master/lectures/19_outliers.ipynb)\n",
    "\n",
    "What is the key difference between regression and classification when it comes to outliers? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "With regression, you need to worry about outliers (extreme values) in your target values. With classification you could still have errors in your target values, but there's less of a well-defined notion of something being \"extreme\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7(e): [**Lecture 21**](https://github.students.cs.ubc.ca/cpsc330-2019w-t2/home/blob/master/lectures/21_communication.ipynb)\n",
    "\n",
    "Consider the following summary I wrote of our cheese analysis, with the target audience of a CPSC 330 student:\n",
    "\n",
    "> In this exam I worked on the [Canadian Cheese Directory dataset](https://open.canada.ca/data/en/dataset/3c16cd48-3ac3-453f-8260-6f745181c83b). I was trying to predict the fat content of a cheese based on numeric features like moisture content, categorical features like the milk type, and text features like the cheese name. I achieved a score of 0.5, which is a lot better than my baseline. And this was all using only 5 folds for cross-validation - imagine how good my model would be with 10 or even 20 folds! I also learned that soft cheeses contain a lot more fat than hard cheeses.\n",
    "\n",
    "Critique this summary. What do you like about it, and what could be improved? Be specific."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "- Positives: Links to dataset, makes clear what the target is, gives examples for types of features.\n",
    "- Negatives: What sort of score - is that $R^2$? What was the baseline? The number of folds is pretty irrelevant here. \n",
    "- Neutrals: Fine to mention the feature importances but should maybe hedge a bit... maybe \"tend to contain\" or \"according to my model\" or \"causes higher predictions\". Also, there is no quantification of \"a lot\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final checks\n",
    "\n",
    "- [ ] Did you check [Piazza](https://piazza.com/class/k1gx4b3djbv3ph?cid=388) for any announcements or clarifications about the exam? \n",
    "- [ ] Did you complete the integrity pledge near the top of this notebook?\n",
    "- [ ] Did you answer all the questions fully? (Some ask for both code and explanations.)\n",
    "- [ ] Did you make note of any course materials you reused code from, after each coding question?\n",
    "- [ ] Did you keep your answers within the posted length limits (usually 3 sentences)?\n",
    "- [ ] Did you run your notebook from beginning to end (\"Restart Kernel and Run All Cells\") to make sure that your entire notebook runs properly?\n",
    "- [ ] Did you push to github.students.cs.ubc.ca and then view your rendered exam in a web browser?\n",
    "- [ ] Did you make sure all your code output is saved/displayed in the notebook?\n",
    "- [x] Did you read this list of final checks?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
